import{_ as s}from"./chunks/9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw.9541447f.js";import{_ as n,o as a,c as l,Q as p}from"./chunks/framework.e90f0c97.js";const h=JSON.parse('{"title":"8：Transformer","description":"","frontmatter":{"prev":{"text":"7.循环神经网络实战","link":"./7.循环神经网络实战.md"},"next":{"text":"9.BERT","link":"./9.BERT.md"}},"headers":[],"relativePath":"md/机器学习/8.Transformer.md","filePath":"md/机器学习/8.Transformer.md"}'),o={name:"md/机器学习/8.Transformer.md"},e=p('<p><img src="'+s+`" alt="9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw"></p><h1 id="_8-transformer" tabindex="-1">8：Transformer <a class="header-anchor" href="#_8-transformer" aria-label="Permalink to &quot;8：Transformer&quot;">​</a></h1><h2 id="🎯-欢迎进入ai的-核心反应堆" tabindex="-1">🎯 欢迎进入AI的&quot;核心反应堆&quot;！ <a class="header-anchor" href="#🎯-欢迎进入ai的-核心反应堆" aria-label="Permalink to &quot;🎯 欢迎进入AI的&quot;核心反应堆&quot;！&quot;">​</a></h2><p>恭喜你！🎉 经过前面所有题目的历练，你已经从AI小白成功进阶。现在，是时候挑战<strong>现代AI的核心引擎</strong>——<strong>Transformer</strong>了！</p><p>这不仅仅是一道题目，更是一次<strong>从入门到精通</strong>的华丽蜕变！从GPT到ChatGPT，从BERT到Stable Diffusion，几乎所有震撼世界的AI模型都离不开这个神奇的架构。</p><blockquote><p>🚀 <strong>激动人心的事实</strong>: 你即将亲手实现支撑整个大语言模型时代的核心技术！</p></blockquote><h2 id="📚-学习目标" tabindex="-1">📚 学习目标 <a class="header-anchor" href="#📚-学习目标" aria-label="Permalink to &quot;📚 学习目标&quot;">​</a></h2><p>✅ <strong>深入理解</strong> Transformer架构的设计哲学 ✅ <strong>掌握注意力机制</strong>的数学原理 ✅ <strong>MiniGPT实战</strong>：理论转化为代码能力 ✅ <strong>培养独立研究</strong>论文的能力</p><h2 id="💡-学习建议" tabindex="-1">💡 学习建议 <a class="header-anchor" href="#💡-学习建议" aria-label="Permalink to &quot;💡 学习建议&quot;">​</a></h2><ol><li><p><strong>理论先行</strong>: 在写代码之前，确保脑海中有清晰的架构图</p></li><li><p><strong>循序渐进</strong>: 从单头注意力到多头，从简单到复杂</p></li><li><p><strong>善用调试</strong>: 每一个tensor的shape变化都要心中有数</p></li><li><p><strong>对比分析</strong>: 调参数，看变化，做一个&quot;超参数猎人&quot;</p></li><li><p><strong>延伸思考</strong>: 想想如何让你的模型更强更快</p></li></ol><p>⚠️ <strong>重要提醒</strong>: 虽然这题很硬核，但完成后你将<strong>从入门直达精通</strong>！这可能是你编程生涯中最有成就感的时刻之一！同时也是面试中的重点题目喔~</p><h2 id="🔥-第一部分-理论基础问答" tabindex="-1">🔥 第一部分：理论基础问答 <a class="header-anchor" href="#🔥-第一部分-理论基础问答" aria-label="Permalink to &quot;🔥 第一部分：理论基础问答&quot;">​</a></h2><h3 id="attention-is-all-you-need" tabindex="-1">Attention is all you need！ <a class="header-anchor" href="#attention-is-all-you-need" aria-label="Permalink to &quot;Attention is all you need！&quot;">​</a></h3><p>在深入代码之前，让我们先&quot;拷问&quot;一下Transformer的灵魂！</p><p>** 必答题清单：**</p><ol><li><p><strong>Transformer的特点</strong>是什么？主要解决什么问题？缺点又是什么？</p><ul><li>🔍 <strong>任务</strong>: 在原论文中找到对应位置并标注</li></ul></li><li><p><strong>Layer Norm vs Batch Norm</strong></p><ul><li>🤔 这两个&quot;标准化兄弟&quot;有什么恩怨情仇？</li></ul></li><li><p><strong>位置编码 (Positional Encoding)</strong></p><ul><li><p><strong>深度解析</strong>: 什么是位置编码？</p></li><li><p>Transformer用了怎样的位置编码？</p></li><li><p>这种设计的优势在哪里？</p></li></ul></li><li><p><strong>Encoder &amp; Decoder 架构解析</strong></p><ul><li><p><strong>画图 + 文字</strong>: 详细说明两个模块的结构</p></li><li><p>数据是如何在其中流动的？</p></li><li><p>🎯 <strong>面试重点</strong>: 务必搞懂每个细节！</p></li></ul></li><li><p><strong>注意力机制核心问题</strong></p><ul><li><p><strong>K, Q, V</strong>分别代表什么？如何变化？</p></li><li><p><strong>Q×K^T</strong>的数学内涵是什么？</p></li><li><p><strong>Scaled Dot-Product Attention</strong> vs <strong>Additive Attention</strong></p></li></ul></li><li><p><strong>自注意力机制的&quot;自&quot;</strong></p><ul><li>这个&quot;自&quot;字体现在哪里？为什么这么设计？</li></ul></li><li><p><strong>可学习参数分析</strong></p><ul><li><p>注意力机制中有需要学习的参数吗？</p></li><li><p>多头注意力中呢？</p></li><li><p>我们希望这些参数学到什么？</p></li></ul></li><li><p><strong>数据流动全解析</strong></p><ul><li><p>文本输入后，各个维度是如何变化的？</p></li><li><p>从token到embedding到输出的完整过程</p></li></ul></li><li><p><strong>BLEU评估指标</strong></p><ul><li>BLEU是什么？在NLP中扮演什么角色？</li></ul></li></ol><hr><h2 id="第二部分-minigpt实战挑战" tabindex="-1">第二部分：MiniGPT实战挑战 <a class="header-anchor" href="#第二部分-minigpt实战挑战" aria-label="Permalink to &quot;第二部分：MiniGPT实战挑战&quot;">​</a></h2><blockquote><p><em>&quot;纸上得来终觉浅，绝知此事要躬行&quot;</em></p></blockquote><p>准备好撸起袖子，手搓一个<strong>迷你版GPT</strong>了吗？</p><h3 id="🎮-实战环境准备" tabindex="-1">🎮 实战环境准备 <a class="header-anchor" href="#🎮-实战环境准备" aria-label="Permalink to &quot;🎮 实战环境准备&quot;">​</a></h3><p><strong>硬件需求</strong>: 强烈建议使用云端GPU（参考第0题白嫖攻略）</p><p><strong>工具</strong>: Jupyter Lab</p><h3 id="_1️⃣-数据集获取" tabindex="-1">1️⃣ 数据集获取 <a class="header-anchor" href="#_1️⃣-数据集获取" aria-label="Permalink to &quot;1️⃣ 数据集获取&quot;">​</a></h3><p><strong>tinyshakespeare数据集</strong>:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">wget</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">wget</span><span style="color:#24292E;"> </span><span style="color:#032F62;">https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</span></span></code></pre></div><blockquote><p>💡 <strong>偷懒指南</strong>: 数据集很小，直接复制粘贴到txt文件也OK！</p></blockquote><h3 id="_2️⃣-超参数配置" tabindex="-1">2️⃣ 超参数配置 <a class="header-anchor" href="#_2️⃣-超参数配置" aria-label="Permalink to &quot;2️⃣ 超参数配置&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch.nn </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> nn</span></span>
<span class="line"><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> torch.nn </span><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> functional </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> F</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> matplotlib.pyplot </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;">## 超参设置（每个参数都有讲究！）</span></span>
<span class="line"><span style="color:#E1E4E8;">batch_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">16</span><span style="color:#E1E4E8;">     </span><span style="color:#6A737D;"># 批处理大小</span></span>
<span class="line"><span style="color:#E1E4E8;">block_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">32</span><span style="color:#E1E4E8;">     </span><span style="color:#6A737D;"># 上下文长度</span></span>
<span class="line"><span style="color:#E1E4E8;">max_iters </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">5000</span><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 训练轮数</span></span>
<span class="line"><span style="color:#E1E4E8;">learning_rate </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">1e-3</span><span style="color:#E1E4E8;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#E1E4E8;">device </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;cuda&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> torch.cuda.is_available() </span><span style="color:#F97583;">else</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;cpu&#39;</span></span>
<span class="line"><span style="color:#E1E4E8;">n_embd </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">64</span><span style="color:#E1E4E8;">         </span><span style="color:#6A737D;"># embedding维度</span></span>
<span class="line"><span style="color:#E1E4E8;">n_head </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">          </span><span style="color:#6A737D;"># 多头注意力头数</span></span>
<span class="line"><span style="color:#E1E4E8;">n_layer </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">         </span><span style="color:#6A737D;"># transformer层数</span></span>
<span class="line"><span style="color:#E1E4E8;">dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">0.0</span><span style="color:#E1E4E8;">       </span><span style="color:#6A737D;"># dropout率</span></span>
<span class="line"><span style="color:#E1E4E8;">torch.manual_seed(</span><span style="color:#79B8FF;">42</span><span style="color:#E1E4E8;">) </span><span style="color:#6A737D;"># 随机种子，保证可复现</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch.nn </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> nn</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> torch.nn </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> functional </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> F</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;">## 超参设置（每个参数都有讲究！）</span></span>
<span class="line"><span style="color:#24292E;">batch_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">16</span><span style="color:#24292E;">     </span><span style="color:#6A737D;"># 批处理大小</span></span>
<span class="line"><span style="color:#24292E;">block_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">32</span><span style="color:#24292E;">     </span><span style="color:#6A737D;"># 上下文长度</span></span>
<span class="line"><span style="color:#24292E;">max_iters </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">5000</span><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 训练轮数</span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1e-3</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#24292E;">device </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;cuda&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> torch.cuda.is_available() </span><span style="color:#D73A49;">else</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;cpu&#39;</span></span>
<span class="line"><span style="color:#24292E;">n_embd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">64</span><span style="color:#24292E;">         </span><span style="color:#6A737D;"># embedding维度</span></span>
<span class="line"><span style="color:#24292E;">n_head </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">          </span><span style="color:#6A737D;"># 多头注意力头数</span></span>
<span class="line"><span style="color:#24292E;">n_layer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">         </span><span style="color:#6A737D;"># transformer层数</span></span>
<span class="line"><span style="color:#24292E;">dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.0</span><span style="color:#24292E;">       </span><span style="color:#6A737D;"># dropout率</span></span>
<span class="line"><span style="color:#24292E;">torch.manual_seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">) </span><span style="color:#6A737D;"># 随机种子，保证可复现</span></span></code></pre></div><h3 id="_3️⃣-数据预处理" tabindex="-1">3️⃣ 数据预处理 <a class="header-anchor" href="#_3️⃣-数据预处理" aria-label="Permalink to &quot;3️⃣ 数据预处理&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 读取莎士比亚文本</span></span>
<span class="line"><span style="color:#F97583;">with</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">open</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;input.txt&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&#39;r&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">encoding</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;utf-8&#39;</span><span style="color:#E1E4E8;">) </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> f:</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> f.read()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;数据集总字符数: </span><span style="color:#79B8FF;">{len</span><span style="color:#E1E4E8;">(text)</span><span style="color:#F97583;">:,</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;前300个字符预览:</span><span style="color:#79B8FF;">\\n{</span><span style="color:#E1E4E8;">text[:</span><span style="color:#79B8FF;">300</span><span style="color:#E1E4E8;">]</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 构建词汇表</span></span>
<span class="line"><span style="color:#E1E4E8;">chars </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">sorted</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">list</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">set</span><span style="color:#E1E4E8;">(text)))</span></span>
<span class="line"><span style="color:#E1E4E8;">vocab_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">len</span><span style="color:#E1E4E8;">(chars)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;词汇表: </span><span style="color:#79B8FF;">{</span><span style="color:#9ECBFF;">&#39;&#39;</span><span style="color:#E1E4E8;">.join(chars)</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;词汇表大小: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">vocab_size</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 简单tokenizer实现</span></span>
<span class="line"><span style="color:#E1E4E8;">stoi </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {ch: i </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i, ch </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">enumerate</span><span style="color:#E1E4E8;">(chars)}</span></span>
<span class="line"><span style="color:#E1E4E8;">itos </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {i: ch </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i, ch </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">enumerate</span><span style="color:#E1E4E8;">(chars)}</span></span>
<span class="line"><span style="color:#E1E4E8;">encode </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">lambda</span><span style="color:#E1E4E8;"> s: [stoi[c] </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> c </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> s]</span></span>
<span class="line"><span style="color:#E1E4E8;">decode </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">lambda</span><span style="color:#E1E4E8;"> l: </span><span style="color:#9ECBFF;">&#39;&#39;</span><span style="color:#E1E4E8;">.join([itos[i] </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> l])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 测试编解码</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;编码测试: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">encode(</span><span style="color:#9ECBFF;">&#39;Hello World!&#39;</span><span style="color:#E1E4E8;">)</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;解码测试: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">decode(encode(</span><span style="color:#9ECBFF;">&#39;Hello World!&#39;</span><span style="color:#E1E4E8;">))</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 读取莎士比亚文本</span></span>
<span class="line"><span style="color:#D73A49;">with</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">open</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;input.txt&#39;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">encoding</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;utf-8&#39;</span><span style="color:#24292E;">) </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> f:</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> f.read()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;数据集总字符数: </span><span style="color:#005CC5;">{len</span><span style="color:#24292E;">(text)</span><span style="color:#D73A49;">:,</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;前300个字符预览:</span><span style="color:#005CC5;">\\n{</span><span style="color:#24292E;">text[:</span><span style="color:#005CC5;">300</span><span style="color:#24292E;">]</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 构建词汇表</span></span>
<span class="line"><span style="color:#24292E;">chars </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">sorted</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">list</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">set</span><span style="color:#24292E;">(text)))</span></span>
<span class="line"><span style="color:#24292E;">vocab_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(chars)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;词汇表: </span><span style="color:#005CC5;">{</span><span style="color:#032F62;">&#39;&#39;</span><span style="color:#24292E;">.join(chars)</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;词汇表大小: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">vocab_size</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 简单tokenizer实现</span></span>
<span class="line"><span style="color:#24292E;">stoi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {ch: i </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, ch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(chars)}</span></span>
<span class="line"><span style="color:#24292E;">itos </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {i: ch </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, ch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(chars)}</span></span>
<span class="line"><span style="color:#24292E;">encode </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">lambda</span><span style="color:#24292E;"> s: [stoi[c] </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> c </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> s]</span></span>
<span class="line"><span style="color:#24292E;">decode </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">lambda</span><span style="color:#24292E;"> l: </span><span style="color:#032F62;">&#39;&#39;</span><span style="color:#24292E;">.join([itos[i] </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> l])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 测试编解码</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;编码测试: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">encode(</span><span style="color:#032F62;">&#39;Hello World!&#39;</span><span style="color:#24292E;">)</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;解码测试: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">decode(encode(</span><span style="color:#032F62;">&#39;Hello World!&#39;</span><span style="color:#24292E;">))</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span></code></pre></div><h3 id="_4️⃣-数据分批处理" tabindex="-1">4️⃣ 数据分批处理 <a class="header-anchor" href="#_4️⃣-数据分批处理" aria-label="Permalink to &quot;4️⃣ 数据分批处理&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">get_batch</span><span style="color:#E1E4E8;">(split):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#9ECBFF;">    生成训练批次数据</span></span>
<span class="line"><span style="color:#9ECBFF;">    </span></span>
<span class="line"><span style="color:#9ECBFF;">    你需要实现：</span></span>
<span class="line"><span style="color:#9ECBFF;">    1. 从训练/验证集中随机采样</span></span>
<span class="line"><span style="color:#9ECBFF;">    2. 生成输入序列x和目标序列y  </span></span>
<span class="line"><span style="color:#9ECBFF;">    3. 返回正确维度的tensor</span></span>
<span class="line"><span style="color:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 你的代码在这里</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">get_batch</span><span style="color:#24292E;">(split):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    生成训练批次数据</span></span>
<span class="line"><span style="color:#032F62;">    </span></span>
<span class="line"><span style="color:#032F62;">    你需要实现：</span></span>
<span class="line"><span style="color:#032F62;">    1. 从训练/验证集中随机采样</span></span>
<span class="line"><span style="color:#032F62;">    2. 生成输入序列x和目标序列y  </span></span>
<span class="line"><span style="color:#032F62;">    3. 返回正确维度的tensor</span></span>
<span class="line"><span style="color:#032F62;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 你的代码在这里</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span></code></pre></div><h3 id="_5️⃣-模型架构实现" tabindex="-1">5️⃣ 模型架构实现 <a class="header-anchor" href="#_5️⃣-模型架构实现" aria-label="Permalink to &quot;5️⃣ 模型架构实现&quot;">​</a></h3><p><strong>🔥 这是整个项目的核心！必须手工实现！</strong></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">Head</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;单头自注意力&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, head_size):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># QKV投影矩阵</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.key </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.query </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">) </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.value </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 下三角mask矩阵（防止看到未来）</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.register_buffer(</span><span style="color:#9ECBFF;">&#39;tril&#39;</span><span style="color:#E1E4E8;">, torch.tril(torch.ones(block_size, block_size)))</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        B, T, C </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> x.shape</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 注意力计算逻辑</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 1. 计算Q, K, V</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 2. 计算注意力分数</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 3. 应用mask</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 4. 加权求和</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">MultiHeadAttention</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;多头注意力：并行处理多个注意力头&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, num_heads, head_size):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.heads </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.ModuleList([Head(head_size) </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(num_heads)])</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.proj </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 多头并行计算与合并</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">FeedForward</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;前馈神经网络：简单而强大&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 实现两层线性变换+激活</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">Block</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;Transformer Block：communication + computation&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 组装完整的transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># LayerNorm + MultiHeadAttention + LayerNorm + FeedForward</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">BigramLanguageModel</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;完整的语言模型&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># embedding表</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.token_embedding_table </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Embedding(vocab_size, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.position_embedding_table </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Embedding(block_size, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 堆叠transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.blocks </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Sequential(</span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;">[Block(n_embd, </span><span style="color:#FFAB70;">n_head</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">n_head) </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(n_layer)])</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.ln_f </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.LayerNorm(n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.lm_head </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, vocab_size)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, idx, targets</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 完整前向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 1. token + position embedding</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 2. 通过transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 3. 输出预测</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 4. 计算损失（如果有target）</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">generate</span><span style="color:#E1E4E8;">(self, idx, max_new_tokens):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#9ECBFF;">&quot;&quot;&quot;文本生成：让AI说话！&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(max_new_tokens):</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 裁剪到block_size</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx_cond </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> idx[:, </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">block_size:]</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 预测下一个token</span></span>
<span class="line"><span style="color:#E1E4E8;">            logits, _ </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">(idx_cond)</span></span>
<span class="line"><span style="color:#E1E4E8;">            logits </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> logits[:, </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, :]  </span><span style="color:#6A737D;"># 只要最后一个时间步</span></span>
<span class="line"><span style="color:#E1E4E8;">            probs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> F.softmax(logits, </span><span style="color:#FFAB70;">dim</span><span style="color:#F97583;">=-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 采样下一个token</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx_next </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.multinomial(probs, </span><span style="color:#FFAB70;">num_samples</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.cat((idx, idx_next), </span><span style="color:#FFAB70;">dim</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> idx</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">Head</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;单头自注意力&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, head_size):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># QKV投影矩阵</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.key </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.query </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">) </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.value </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 下三角mask矩阵（防止看到未来）</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.register_buffer(</span><span style="color:#032F62;">&#39;tril&#39;</span><span style="color:#24292E;">, torch.tril(torch.ones(block_size, block_size)))</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        B, T, C </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x.shape</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 注意力计算逻辑</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 1. 计算Q, K, V</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 2. 计算注意力分数</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 3. 应用mask</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 4. 加权求和</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">MultiHeadAttention</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;多头注意力：并行处理多个注意力头&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, num_heads, head_size):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.heads </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.ModuleList([Head(head_size) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_heads)])</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 多头并行计算与合并</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">FeedForward</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;前馈神经网络：简单而强大&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现两层线性变换+激活</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">Block</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;Transformer Block：communication + computation&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 组装完整的transformer块</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># LayerNorm + MultiHeadAttention + LayerNorm + FeedForward</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">BigramLanguageModel</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;完整的语言模型&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># embedding表</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.token_embedding_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Embedding(vocab_size, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.position_embedding_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Embedding(block_size, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 堆叠transformer块</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.blocks </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Sequential(</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">[Block(n_embd, </span><span style="color:#E36209;">n_head</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">n_head) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_layer)])</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.ln_f </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.LayerNorm(n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.lm_head </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, vocab_size)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, idx, targets</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 完整前向传播</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 1. token + position embedding</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 2. 通过transformer块</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 3. 输出预测</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 4. 计算损失（如果有target）</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">generate</span><span style="color:#24292E;">(self, idx, max_new_tokens):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;文本生成：让AI说话！&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(max_new_tokens):</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 裁剪到block_size</span></span>
<span class="line"><span style="color:#24292E;">            idx_cond </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> idx[:, </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">block_size:]</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 预测下一个token</span></span>
<span class="line"><span style="color:#24292E;">            logits, _ </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">(idx_cond)</span></span>
<span class="line"><span style="color:#24292E;">            logits </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> logits[:, </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, :]  </span><span style="color:#6A737D;"># 只要最后一个时间步</span></span>
<span class="line"><span style="color:#24292E;">            probs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> F.softmax(logits, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 采样下一个token</span></span>
<span class="line"><span style="color:#24292E;">            idx_next </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.multinomial(probs, </span><span style="color:#E36209;">num_samples</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            idx </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.cat((idx, idx_next), </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> idx</span></span></code></pre></div><h3 id="_6️⃣-模型评估-📊" tabindex="-1">6️⃣ 模型评估 📊 <a class="header-anchor" href="#_6️⃣-模型评估-📊" aria-label="Permalink to &quot;6️⃣ 模型评估 📊&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">@torch.no_grad</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">estimate_loss</span><span style="color:#E1E4E8;">():</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;评估训练和验证损失&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {}</span></span>
<span class="line"><span style="color:#E1E4E8;">    model.eval()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 计算平均损失</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    model.train()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> out</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">@torch.no_grad</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">estimate_loss</span><span style="color:#24292E;">():</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;评估训练和验证损失&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {}</span></span>
<span class="line"><span style="color:#24292E;">    model.eval()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 计算平均损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    model.train()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> out</span></span></code></pre></div><h3 id="_7️⃣-模型训练" tabindex="-1">7️⃣ 模型训练 <a class="header-anchor" href="#_7️⃣-模型训练" aria-label="Permalink to &quot;7️⃣ 模型训练&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 实例化模型</span></span>
<span class="line"><span style="color:#E1E4E8;">model </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> BigramLanguageModel().to(device)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;模型参数量: </span><span style="color:#79B8FF;">{sum</span><span style="color:#E1E4E8;">(p.numel() </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> p </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> model.parameters())</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">1e6</span><span style="color:#F97583;">:.2f</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">M&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 训练循环</span></span>
<span class="line"><span style="color:#E1E4E8;">optimizer </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.optim.AdamW(model.parameters(), </span><span style="color:#FFAB70;">lr</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">learning_rate)</span></span>
<span class="line"><span style="color:#E1E4E8;">train_losses, val_losses </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">iter</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(max_iters):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 训练循环实现</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 1. 获取batch</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 2. 前向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 3. 计算损失</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 4. 反向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 5. 参数更新</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 6. 定期评估</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 绘制损失曲线</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.figure(</span><span style="color:#FFAB70;">figsize</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">5</span><span style="color:#E1E4E8;">))</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.plot(train_losses, </span><span style="color:#FFAB70;">label</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;Train Loss&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">color</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;#FF6B6B&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.plot(val_losses, </span><span style="color:#FFAB70;">label</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;Validation Loss&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">color</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;#4ECDC4&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.xlabel(</span><span style="color:#9ECBFF;">&#39;Iteration&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.ylabel(</span><span style="color:#9ECBFF;">&#39;Loss&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.title(</span><span style="color:#9ECBFF;">&#39;Training Progress: Loss Curves&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.legend()</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.grid(</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">alpha</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0.3</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.savefig(</span><span style="color:#9ECBFF;">&#39;loss_plot.png&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">dpi</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">300</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bbox_inches</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;tight&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 生成莎士比亚风格文本</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;AI莎士比亚开始创作...&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">context </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.zeros((</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">), </span><span style="color:#FFAB70;">dtype</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">torch.long, </span><span style="color:#FFAB70;">device</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">device)</span></span>
<span class="line"><span style="color:#E1E4E8;">generated_text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> decode(model.generate(context, </span><span style="color:#FFAB70;">max_new_tokens</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2000</span><span style="color:#E1E4E8;">)[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">].tolist())</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(generated_text)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 实例化模型</span></span>
<span class="line"><span style="color:#24292E;">model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> BigramLanguageModel().to(device)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;模型参数量: </span><span style="color:#005CC5;">{sum</span><span style="color:#24292E;">(p.numel() </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> p </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> model.parameters())</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">1e6</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">M&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 训练循环</span></span>
<span class="line"><span style="color:#24292E;">optimizer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.optim.AdamW(model.parameters(), </span><span style="color:#E36209;">lr</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">learning_rate)</span></span>
<span class="line"><span style="color:#24292E;">train_losses, val_losses </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">iter</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(max_iters):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 训练循环实现</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 1. 获取batch</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 2. 前向传播</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 3. 计算损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 4. 反向传播</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 5. 参数更新</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 6. 定期评估</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 绘制损失曲线</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(train_losses, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train Loss&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">color</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;#FF6B6B&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(val_losses, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Validation Loss&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">color</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;#4ECDC4&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iteration&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Loss&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Training Progress: Loss Curves&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.grid(</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">, </span><span style="color:#E36209;">alpha</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.3</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.savefig(</span><span style="color:#032F62;">&#39;loss_plot.png&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dpi</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">300</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bbox_inches</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;tight&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 生成莎士比亚风格文本</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;AI莎士比亚开始创作...&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">context </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.zeros((</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">), </span><span style="color:#E36209;">dtype</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">torch.long, </span><span style="color:#E36209;">device</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">device)</span></span>
<span class="line"><span style="color:#24292E;">generated_text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> decode(model.generate(context, </span><span style="color:#E36209;">max_new_tokens</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2000</span><span style="color:#24292E;">)[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].tolist())</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(generated_text)</span></span></code></pre></div><h3 id="_8️⃣-结果分析" tabindex="-1">8️⃣ 结果分析 <a class="header-anchor" href="#_8️⃣-结果分析" aria-label="Permalink to &quot;8️⃣ 结果分析&quot;">​</a></h3><p><strong>回答以下问题：</strong></p><ol><li><p><strong>Validation Loss收敛值</strong>是多少？</p></li><li><p><strong>MiniGPT参数量</strong>统计（应该&lt;1M）</p></li><li><p><strong>显存占用</strong>情况（应该&lt;1G）</p></li></ol><h3 id="_9️⃣-挑战性进阶问题" tabindex="-1">9️⃣ 挑战性进阶问题 <a class="header-anchor" href="#_9️⃣-挑战性进阶问题" aria-label="Permalink to &quot;9️⃣ 挑战性进阶问题&quot;">​</a></h3><ol><li><p><strong>RoPE vs 正弦位置编码</strong></p><ul><li><p>为什么现代GPT使用<strong>Rotary Position Embedding</strong>？</p></li><li><p>尝试在MiniGPT中实现RoPE并对比性能！</p></li></ul></li><li><p><strong>LayerNorm位置之争</strong></p><ul><li><p><strong>Pre-LN</strong> vs <strong>Post-LN</strong>：为什么前者更稳定？</p></li><li><p>修改代码实现Pre-LN架构并分析训练稳定性！</p></li></ul></li><li><p><strong>计算复杂度分析</strong></p><ul><li><p>当block_size增加到128时会发生什么？</p></li><li><p>尝试**梯度检查点(Gradient Checkpointing)**减少显存占用！</p></li></ul></li><li><p><strong>FlashAttention算法</strong></p><ul><li>了解这个让Transformer飞起来的神奇算法！</li></ul></li></ol><hr><h2 id="⚠️-重要提醒" tabindex="-1">⚠️ 重要提醒 <a class="header-anchor" href="#⚠️-重要提醒" aria-label="Permalink to &quot;⚠️ 重要提醒&quot;">​</a></h2><blockquote><p><strong>AI工具使用</strong>: 本题<strong>强烈建议纯手工实现</strong>！这可能是你最后一次有机会完全从零手撸这么核心的算法了，好好珍惜这个过程吧！</p></blockquote><hr><h2 id="提交要求" tabindex="-1">提交要求 <a class="header-anchor" href="#提交要求" aria-label="Permalink to &quot;提交要求&quot;">​</a></h2><h3 id="提交内容" tabindex="-1">提交内容 <a class="header-anchor" href="#提交内容" aria-label="Permalink to &quot;提交内容&quot;">​</a></h3><ul><li><p><strong>代码文件</strong>: <code>ml-8-姓名-学号.py</code></p></li><li><p><strong>理论答案</strong>: <code>ml-8-姓名-学号.md</code></p></li><li><p>压缩包提交</p></li></ul><h3 id="提交方式" tabindex="-1">提交方式 <a class="header-anchor" href="#提交方式" aria-label="Permalink to &quot;提交方式&quot;">​</a></h3><ul><li><p><strong>邮箱</strong>: <code>gimmerml401@163.com</code></p></li><li><p><strong>主题</strong>: <code>8-姓名-学号</code></p></li></ul><blockquote><p>出题人：百事可乐</p><p>QQ：2465800571</p></blockquote>`,55),t=[e];function c(r,y,E,i,F,d){return a(),l("div",null,t)}const C=n(o,[["render",c]]);export{h as __pageData,C as default};
