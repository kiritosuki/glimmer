import{_ as a}from"./chunks/9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw.9541447f.js";import{_ as l,o as e,c as s,Q as n}from"./chunks/framework.e90f0c97.js";const q=JSON.parse('{"title":"9：BERT","description":"","frontmatter":{"prev":{"text":"8.Transformer","link":"./8.Transformer.md"},"next":false},"headers":[],"relativePath":"md/机器学习/9.BERT.md","filePath":"md/机器学习/9.BERT.md"}'),o={name:"md/机器学习/9.BERT.md"},t=n('<p><img src="'+a+`" alt="9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw"></p><h1 id="_9-bert" tabindex="-1">9：BERT <a class="header-anchor" href="#_9-bert" aria-label="Permalink to &quot;9：BERT&quot;">​</a></h1><h2 id="🎉-恭喜抵达终点线" tabindex="-1">🎉 恭喜抵达终点线！ <a class="header-anchor" href="#🎉-恭喜抵达终点线" aria-label="Permalink to &quot;🎉 恭喜抵达终点线！&quot;">​</a></h2><p>哇！恭喜你坚持到了最后一题！这一路走来，从线性回归的小白，到现在能够挑战BERT这样的经典模型，你的成长有目共睹！</p><p>这道题不仅是对你学习成果的检验，更是一次<strong>站在巨人肩膀上</strong>的体验。BERT作为NLP领域的里程碑之作，它的设计思想至今仍在影响着整个AI界。</p><blockquote><p>🎯 <strong>最后的挑战</strong>: 让我们一起探索这个改变了整个自然语言处理格局的传奇模型！</p></blockquote><h2 id="📚-第一部分-bert论文深度解读" tabindex="-1">📚 第一部分：BERT论文深度解读 <a class="header-anchor" href="#📚-第一部分-bert论文深度解读" aria-label="Permalink to &quot;📚 第一部分：BERT论文深度解读&quot;">​</a></h2><h3 id="论文研读任务" tabindex="-1">论文研读任务 <a class="header-anchor" href="#论文研读任务" aria-label="Permalink to &quot;论文研读任务&quot;">​</a></h3><p><strong>论文链接</strong>: <a href="https://arxiv.org/pdf/1810.04805" target="_blank" rel="noreferrer">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p><blockquote><p>💡 <strong>阅读指南</strong>: 这是<strong>芝麻街系列</strong>的经典之作！作者巧妙融合前人成果，取得了惊艳效果。这种&quot;站在巨人肩膀上&quot;的做法很值得我们学习！</p></blockquote><h3 id="核心问题解析" tabindex="-1">核心问题解析 <a class="header-anchor" href="#核心问题解析" aria-label="Permalink to &quot;核心问题解析&quot;">​</a></h3><p><strong>必答题清单：</strong></p><ol><li><p><strong>论文结构分析</strong></p><ul><li><p>论文分为几个部分？</p></li><li><p>每部分主要解决什么问题？</p></li><li><p>各部分之间的逻辑关系如何？</p></li></ul></li><li><p><strong>Input Embedding策略</strong></p><ul><li><p>BERT采用了什么embedding方法？</p></li><li><p>你认为这样做有什么好处？</p></li><li><p>相比传统方法有什么创新？</p></li></ul></li><li><p><strong>Tokenization谜题</strong> 在附录A.1的例子中：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">为什么是 &quot;flight ##less&quot; 而不是直接写 &quot;flightless&quot;？</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">为什么是 &quot;flight ##less&quot; 而不是直接写 &quot;flightless&quot;？</span></span></code></pre></div><ul><li><p>这个&quot;##&quot;符号有什么特殊含义？</p></li><li><p>这种设计解决了什么问题？</p></li></ul></li><li><p><strong>模型架构解析</strong></p><ul><li><p>BERT的基本架构是怎样的？</p></li><li><p>它与Transformer的关系如何？</p></li><li><p>有哪些关键的改进和创新？</p></li></ul></li><li><p><strong>Pre-train &amp; Fine-tune策略</strong></p><ul><li><p>**预训练(Pre-train)**的含义是什么？</p></li><li><p>**微调(Fine-tune)**又是什么？</p></li><li><p>BERT是如何巧妙利用这两个阶段的？</p></li></ul></li><li><p><strong>GLUE评估基准</strong></p><ul><li><p>GLUE分数是什么？</p></li><li><p>它评估了模型的哪些能力？</p></li><li><p>为什么它在NLP领域这么重要？</p></li></ul></li><li><p><strong>BERT家族谱系</strong> <em>(需要自行搜集资料)</em></p><ul><li><p>BERT衍生出了哪些&quot;后代&quot;模型？</p></li><li><p>这些模型的发展趋势是什么？</p></li><li><p>你觉得未来的发展方向在哪里？</p></li></ul></li></ol><h3 id="拓展研究-进阶挑战" tabindex="-1">拓展研究（进阶挑战） <a class="header-anchor" href="#拓展研究-进阶挑战" aria-label="Permalink to &quot;拓展研究（进阶挑战）&quot;">​</a></h3><ol><li><p><strong>实验设计精髓</strong></p><ul><li><p>作者如何设计实验证明方法有效性？</p></li><li><p>**消融实验(Ablation Study)**的巧思在哪里？</p></li><li><p>实验结果如何支撑核心论点？</p></li></ul></li><li><p><strong>GPT vs BERT对比研究</strong> 推荐阅读：<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noreferrer">《Improving Language Understanding by Generative Pre-Training》</a></p><ul><li><p>GPT和BERT在思路上有何本质区别？</p></li><li><p>各自的优势和局限性是什么？</p></li><li><p>为什么后来GPT系列&quot;逆袭&quot;了？</p></li></ul></li><li><p><strong>阅读感悟</strong></p><ul><li><p>读完这几篇经典论文后，你最大的收获是什么？</p></li><li><p>对AI研究有了哪些新的认识？</p></li><li><p>对你未来的学习和研究有什么启发？</p></li></ul></li></ol><hr><h2 id="💻-第二部分-自然语言推理实战" tabindex="-1">💻 第二部分：自然语言推理实战 <a class="header-anchor" href="#💻-第二部分-自然语言推理实战" aria-label="Permalink to &quot;💻 第二部分：自然语言推理实战&quot;">​</a></h2><h3 id="任务背景" tabindex="-1">任务背景 <a class="header-anchor" href="#任务背景" aria-label="Permalink to &quot;任务背景&quot;">​</a></h3><p><strong>自然语言推理(NLI)</strong>，也叫<strong>文本蕴含识别(RTE)</strong>，是NLP的核心任务之一！</p><p><strong>任务定义</strong>: 给定两个句子：</p><ul><li><p><strong>前提(Premise)</strong></p></li><li><p><strong>假设(Hypothesis)</strong></p></li></ul><p>判断它们的关系：</p><ul><li><p><strong>矛盾(Contradiction)</strong>: 前提与假设冲突</p></li><li><p><strong>蕴含(Entailment)</strong>: 前提支持假设</p></li><li><p><strong>中立(Neutral)</strong>: 前提与假设无关</p></li></ul><h3 id="数据集示例" tabindex="-1">数据集示例 <a class="header-anchor" href="#数据集示例" aria-label="Permalink to &quot;数据集示例&quot;">​</a></h3><div class="language-plaintext vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">前提: A person on a horse jumps over a broken down airplane.</span></span>
<span class="line"><span style="color:#e1e4e8;">假设: A person is training his horse for a competition.</span></span>
<span class="line"><span style="color:#e1e4e8;">关系: neutral</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">前提: Children smiling and waving at camera  </span></span>
<span class="line"><span style="color:#e1e4e8;">假设: They are smiling at their parents</span></span>
<span class="line"><span style="color:#e1e4e8;">关系: neutral</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">前提: A boy is jumping on skateboard in the middle of a red bridge.</span></span>
<span class="line"><span style="color:#e1e4e8;">假设: The boy does a skateboarding trick.</span></span>
<span class="line"><span style="color:#e1e4e8;">关系: entailment</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">前提: A person on a horse jumps over a broken down airplane.</span></span>
<span class="line"><span style="color:#24292e;">假设: A person is training his horse for a competition.</span></span>
<span class="line"><span style="color:#24292e;">关系: neutral</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">前提: Children smiling and waving at camera  </span></span>
<span class="line"><span style="color:#24292e;">假设: They are smiling at their parents</span></span>
<span class="line"><span style="color:#24292e;">关系: neutral</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">前提: A boy is jumping on skateboard in the middle of a red bridge.</span></span>
<span class="line"><span style="color:#24292e;">假设: The boy does a skateboarding trick.</span></span>
<span class="line"><span style="color:#24292e;">关系: entailment</span></span></code></pre></div><h3 id="🎯-实战目标" tabindex="-1">🎯 实战目标 <a class="header-anchor" href="#🎯-实战目标" aria-label="Permalink to &quot;🎯 实战目标&quot;">​</a></h3><p><strong>核心任务</strong>: 训练一个分类模型，准确判断句子对之间的逻辑关系！</p><p><strong>评价指标</strong>: 测试集上的<strong>准确率(Accuracy)</strong></p><p><strong>实现策略</strong>:</p><ul><li><p><strong>模型选择</strong>: 不限制架构和参数量，选择最适合的！</p></li><li><p><strong>数据处理</strong>: 预处理、训练技巧、超参数调优都很重要！</p></li><li><p><strong>创新设计</strong>: 充分发挥想象力！</p></li></ul><h3 id="数据获取" tabindex="-1">数据获取 <a class="header-anchor" href="#数据获取" aria-label="Permalink to &quot;数据获取&quot;">​</a></h3><p><strong>数据集链接</strong>: <a href="https://www.kaggle.com/datasets/qiqiyiyiguo/glimmer-2025-ml-9" target="_blank" rel="noreferrer">Kaggle Datasets</a></p><ul><li><p><strong>文件名</strong>: <code>dataset/classification.txt</code></p></li><li><p><strong>任务</strong>: 自行按合适比例划分训练集和测试集</p></li></ul><h3 id="实战笔记要求" tabindex="-1">实战笔记要求 <a class="header-anchor" href="#实战笔记要求" aria-label="Permalink to &quot;实战笔记要求&quot;">​</a></h3><p><strong>笔记文档内容应包括</strong>:</p><ul><li><p><strong>项目实现逻辑</strong>: 你的整体思路和架构设计</p></li><li><p><strong>问题与解决方案</strong>: 实现中遇到的坑和填坑经验</p></li><li><p><strong>收获与思考</strong>: 在项目中的成长和感悟</p></li><li><p><strong>实验结果分析</strong>: 模型性能和改进方向</p></li></ul><blockquote><p><strong>LaTeX公式</strong>: 内部公式建议使用LaTeX格式，让文档更专业！</p></blockquote><h2 id="⚠️-注意事项" tabindex="-1">⚠️ 注意事项 <a class="header-anchor" href="#⚠️-注意事项" aria-label="Permalink to &quot;⚠️ 注意事项&quot;">​</a></h2><h3 id="ai工具使用政策" tabindex="-1">AI工具使用政策 <a class="header-anchor" href="#ai工具使用政策" aria-label="Permalink to &quot;AI工具使用政策&quot;">​</a></h3><p><strong>适度使用AIGC工具</strong>是被允许的，但是！<strong>不仅要知其然，更要知其所以然！</strong></p><h3 id="学习建议" tabindex="-1">学习建议 <a class="header-anchor" href="#学习建议" aria-label="Permalink to &quot;学习建议&quot;">​</a></h3><ol><li><p>经典文献不可不读</p><ul><li>虽然技术贴很有用，但原始论文更重要！</li></ul></li><li><p>保持探索精神</p><ul><li>读不懂时多查资料，多思考</li></ul></li><li><p>相信自己，勇敢尝试</p><ul><li>你已经走到这里了，一定可以的！</li></ul></li></ol><h2 id="提交要求" tabindex="-1">提交要求 <a class="header-anchor" href="#提交要求" aria-label="Permalink to &quot;提交要求&quot;">​</a></h2><h3 id="提交内容" tabindex="-1">提交内容 <a class="header-anchor" href="#提交内容" aria-label="Permalink to &quot;提交内容&quot;">​</a></h3><ul><li><p><strong>理论部分</strong>: <code>ml-9-姓名-学号.md</code> (第1题答案 + 第2题实战笔记)</p></li><li><p><strong>代码文件</strong>: <code>ml-9-姓名-学号.py</code> (或完整项目文件夹)</p></li><li><p>所有文件压缩后提交</p></li></ul><h3 id="提交方式" tabindex="-1">提交方式 <a class="header-anchor" href="#提交方式" aria-label="Permalink to &quot;提交方式&quot;">​</a></h3><ul><li><p><strong>邮箱</strong>: <code>gimmerml401@163.com</code></p></li><li><p><strong>主题</strong>: <code>9-姓名-学号</code></p></li></ul><blockquote><p>出题人：百事可乐</p><p>QQ：2465800571</p></blockquote>`,48),i=[t];function r(p,c,g,d,h,u){return e(),s("div",null,i)}const f=l(o,[["render",r]]);export{q as __pageData,f as default};
