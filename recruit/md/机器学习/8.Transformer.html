<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>8：Transformer | 2025招新</title>
    <meta name="description" content="A VitePress site">
    <link rel="preload stylesheet" href="/assets/style.bb0f7f9b.css" as="style">
    
    <script type="module" src="/assets/app.47be2288.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.2ed14f66.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.e90f0c97.js">
    <link rel="modulepreload" href="/assets/chunks/theme.b56f78f2.js">
    <link rel="modulepreload" href="/assets/chunks/9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw.9541447f.js">
    <link rel="modulepreload" href="/assets/md_机器学习_8.Transformer.md.b9a92191.lean.js">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <link rel="icon" href="/image/favicon.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5a346dfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5a346dfe data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-a0fd61f4><div class="container" data-v-a0fd61f4><div class="title" data-v-a0fd61f4><div class="VPNavBarTitle has-sidebar" data-v-a0fd61f4 data-v-86d1bed8><a class="title" href="/" data-v-86d1bed8><!--[--><!--]--><!--[--><img class="VPImage logo" src="/image/favicon.png" alt data-v-8426fc1a><!--]--><!--[-->微光工作室<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-a0fd61f4><div class="curtain" data-v-a0fd61f4></div><div class="content-body" data-v-a0fd61f4><!--[--><!--]--><div class="VPNavBarSearch search" data-v-a0fd61f4><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-a0fd61f4 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/md/%E6%8B%9B%E6%96%B0%E8%AF%B4%E6%98%8E.html" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>招新说明</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>日常基础</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-01%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9F.html" data-v-43f1e123><!--[-->日常-01：什么是计算机？<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-02%EF%BC%9Amarkdown.html" data-v-43f1e123><!--[-->日常-02：markdown<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-03%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA.html" data-v-43f1e123><!--[-->日常-03：数据的表示<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-04%EF%BC%9AIDE%E7%BC%96%E7%A8%8B%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87.html" data-v-43f1e123><!--[-->日常-04：IDE编程前的准备<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-05%EF%BC%9A%E4%BA%86%E8%A7%A3linux.html" data-v-43f1e123><!--[-->日常-05：了解linux<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-06%EF%BC%9A%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86.html" data-v-43f1e123><!--[-->日常-06：代码管理<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-07%EF%BC%9Aloafer%E6%83%B3%E6%89%93%E6%B4%BE(%E7%BD%91%E7%BB%9C).html" data-v-43f1e123><!--[-->日常-07：loafer想打派(网络)<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>计算机系统</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/计算机系统/" data-v-43f1e123><!--[-->计算机系统简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>计算机系统</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-EASY-01%20What&#39;s%20your%20name.html" data-v-43f1e123><!--[-->CS-EASY-01 What&#39;s your name<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-EASY-02%20%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html" data-v-43f1e123><!--[-->CS-EASY-02 基础数据结构<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-EASY-03%20%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%BC%95%E5%85%A5.html" data-v-43f1e123><!--[-->CS-EASY-03 编译原理引入<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-MEDIUM-01-%E4%BD%8D%E8%AE%A1%E7%AE%97.html" data-v-43f1e123><!--[-->CS-MEDIUM-01-位计算<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-MEDIUM-02-%E6%B5%AE%E7%82%B9%E6%95%B0.html" data-v-43f1e123><!--[-->CS-MEDIUM-02-浮点数<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-MEDIUM-03%20Read%20From%20Memory.html" data-v-43f1e123><!--[-->CS-MEDIUM-03 Read From Memory<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-MEDIUM-04%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%AF%86%E4%B8%8E%E5%AE%9E%E9%AA%8C.html" data-v-43f1e123><!--[-->CS-MEDIUM-04 计算机网络常识与实验<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/CS-HARD-01-cache.html" data-v-43f1e123><!--[-->CS-HARD-01-cache<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>前端</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/前端/" data-v-43f1e123><!--[-->前端简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>前端</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T1.%E5%88%9D%E8%AF%86HTML.html" data-v-43f1e123><!--[-->前端方向-01：初识HTML<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T2.%E4%BA%86%E8%A7%A3%E7%BD%91%E9%A1%B5F12%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7.html" data-v-43f1e123><!--[-->前端方向-02：了解网页F12开发者工具<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T3.CSS%E5%88%9D%E8%AF%86.html" data-v-43f1e123><!--[-->前端方向-03：CSS初识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T4.Javascript%E5%85%A5%E9%97%A8%E5%92%8C%E8%BF%9B%E9%98%B6.html" data-v-43f1e123><!--[-->前端方向-04：Javascript入门和进阶<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T5.%E5%88%B6%E4%BD%9Cblog.html" data-v-43f1e123><!--[-->前端方向-05：制作blog<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T6.%E7%AC%AC%E4%B8%89%E6%96%B9API&amp;&amp;%E6%8E%92%E5%BA%8F.html" data-v-43f1e123><!--[-->前端方向-06：第三方API&amp;&amp;排序<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T7.Node.js.html" data-v-43f1e123><!--[-->前端方向-07：Node.js<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T8.VitePress.html" data-v-43f1e123><!--[-->前端方向-08：VitePress<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%89%8D%E7%AB%AF/T9.Vue%E7%9A%84%E5%AD%A6%E4%B9%A0.html" data-v-43f1e123><!--[-->前端方向-09：Vue的学习<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>后端</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/后端/" data-v-43f1e123><!--[-->后端简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>JAVA</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java01-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html" data-v-43f1e123><!--[-->Java01-环境搭建<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java02-%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C.html" data-v-43f1e123><!--[-->Java02-程序运行<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java03-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html" data-v-43f1e123><!--[-->Java03-数据类型与数据结构<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java04-%E6%8E%A7%E5%88%B6%E6%B5%81.html" data-v-43f1e123><!--[-->Java04-控制流<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java05-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.html" data-v-43f1e123><!--[-->Java05-面向对象<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java06-%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E4%B8%8E%E5%A4%9A%E6%80%81.html" data-v-43f1e123><!--[-->Java06-封装继承与多态<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/java07-%E9%9B%86%E5%90%88%E4%B8%8E%E6%B3%9B%E5%9E%8B.html" data-v-43f1e123><!--[-->java07-集合与泛型<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/java08-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8EStream%E6%B5%81.html" data-v-43f1e123><!--[-->java08-异常处理与Stream流<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/java09-IO%E6%B5%81.html" data-v-43f1e123><!--[-->java09-IO流<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E5%90%8E%E7%AB%AF/Java10-%E5%BF%AB%E9%80%92%E5%8F%96%E4%BB%B6%E7%A0%81%E6%9F%A5%E8%AF%A2%E9%A1%B9%E7%9B%AE.html" data-v-43f1e123><!--[-->Java10-快递取件码查询项目<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>机器学习</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/md/机器学习/" data-v-43f1e123><!--[-->机器学习简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>机器学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/0.%E8%B7%A8%E5%87%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AD%A5.html" data-v-43f1e123><!--[-->0.跨出深度学习的第一步<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.%E5%9F%BA%E7%A1%80%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html" data-v-43f1e123><!--[-->1.基础的线性回归<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2.%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%90%86%E8%AE%BA.html" data-v-43f1e123><!--[-->2.多层感知机理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AE%9E%E6%88%98.html" data-v-43f1e123><!--[-->3.多层感知机实战<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html" data-v-43f1e123><!--[-->4.卷积神经网络理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5.%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98.html" data-v-43f1e123><!--[-->5.卷积神经网络实战<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html" data-v-43f1e123><!--[-->6.循环神经网络理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98.html" data-v-43f1e123><!--[-->7.循环神经网络实战<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link active" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/8.Transformer.html" data-v-43f1e123><!--[-->8.Transformer<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/9.BERT.html" data-v-43f1e123><!--[-->9.BERT<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-a0fd61f4 data-v-e6aabb21><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-e6aabb21 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-a0fd61f4 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://glimmer.org.cn/" aria-label="slack" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Slack</title><path d="M5.042 15.165a2.528 2.528 0 0 1-2.52 2.523A2.528 2.528 0 0 1 0 15.165a2.527 2.527 0 0 1 2.522-2.52h2.52v2.52zM6.313 15.165a2.527 2.527 0 0 1 2.521-2.52 2.527 2.527 0 0 1 2.521 2.52v6.313A2.528 2.528 0 0 1 8.834 24a2.528 2.528 0 0 1-2.521-2.522v-6.313zM8.834 5.042a2.528 2.528 0 0 1-2.521-2.52A2.528 2.528 0 0 1 8.834 0a2.528 2.528 0 0 1 2.521 2.522v2.52H8.834zM8.834 6.313a2.528 2.528 0 0 1 2.521 2.521 2.528 2.528 0 0 1-2.521 2.521H2.522A2.528 2.528 0 0 1 0 8.834a2.528 2.528 0 0 1 2.522-2.521h6.312zM18.956 8.834a2.528 2.528 0 0 1 2.522-2.521A2.528 2.528 0 0 1 24 8.834a2.528 2.528 0 0 1-2.522 2.521h-2.522V8.834zM17.688 8.834a2.528 2.528 0 0 1-2.523 2.521 2.527 2.527 0 0 1-2.52-2.521V2.522A2.527 2.527 0 0 1 15.165 0a2.528 2.528 0 0 1 2.523 2.522v6.312zM15.165 18.956a2.528 2.528 0 0 1 2.523 2.522A2.528 2.528 0 0 1 15.165 24a2.527 2.527 0 0 1-2.52-2.522v-2.522h2.52zM15.165 17.688a2.527 2.527 0 0 1-2.52-2.523 2.526 2.526 0 0 1 2.52-2.52h6.313A2.527 2.527 0 0 1 24 15.165a2.528 2.528 0 0 1-2.522 2.523h-6.313z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-a0fd61f4 data-v-40855f84 data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9c007e85><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-9c007e85><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-40855f84><div class="item appearance" data-v-40855f84><p class="label" data-v-40855f84>Appearance</p><div class="appearance-action" data-v-40855f84><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-40855f84 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-40855f84><div class="item social-links" data-v-40855f84><div class="VPSocialLinks social-links-list" data-v-40855f84 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://glimmer.org.cn/" aria-label="slack" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Slack</title><path d="M5.042 15.165a2.528 2.528 0 0 1-2.52 2.523A2.528 2.528 0 0 1 0 15.165a2.527 2.527 0 0 1 2.522-2.52h2.52v2.52zM6.313 15.165a2.527 2.527 0 0 1 2.521-2.52 2.527 2.527 0 0 1 2.521 2.52v6.313A2.528 2.528 0 0 1 8.834 24a2.528 2.528 0 0 1-2.521-2.522v-6.313zM8.834 5.042a2.528 2.528 0 0 1-2.521-2.52A2.528 2.528 0 0 1 8.834 0a2.528 2.528 0 0 1 2.521 2.522v2.52H8.834zM8.834 6.313a2.528 2.528 0 0 1 2.521 2.521 2.528 2.528 0 0 1-2.521 2.521H2.522A2.528 2.528 0 0 1 0 8.834a2.528 2.528 0 0 1 2.522-2.521h6.312zM18.956 8.834a2.528 2.528 0 0 1 2.522-2.521A2.528 2.528 0 0 1 24 8.834a2.528 2.528 0 0 1-2.522 2.521h-2.522V8.834zM17.688 8.834a2.528 2.528 0 0 1-2.523 2.521 2.527 2.527 0 0 1-2.52-2.521V2.522A2.527 2.527 0 0 1 15.165 0a2.528 2.528 0 0 1 2.523 2.522v6.312zM15.165 18.956a2.528 2.528 0 0 1 2.523 2.522A2.528 2.528 0 0 1 15.165 24a2.527 2.527 0 0 1-2.52-2.522v-2.522h2.52zM15.165 17.688a2.527 2.527 0 0 1-2.52-2.523 2.526 2.526 0 0 1 2.52-2.52h6.313A2.527 2.527 0 0 1 24 15.165a2.528 2.528 0 0 1-2.522 2.523h-6.313z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-a0fd61f4 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-5a346dfe data-v-79c8c1df><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-79c8c1df><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-79c8c1df><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-79c8c1df>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-79c8c1df data-v-1c15a60a><button data-v-1c15a60a>Return to top</button><!----></div></div><aside class="VPSidebar" data-v-5a346dfe data-v-b00e2fdd><div class="curtain" data-v-b00e2fdd></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b00e2fdd><span class="visually-hidden" id="sidebar-aria-label" data-v-b00e2fdd> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-b00e2fdd><section class="VPSidebarItem level-0 is-link has-active" data-v-b00e2fdd data-v-e31bd47b><div class="item" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/机器学习/" data-v-e31bd47b><!--[--><h2 class="text" data-v-e31bd47b>机器学习</h2><!--]--></a><!----></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/机器学习/" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>机器学习简介</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 has-active" data-v-e31bd47b data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h3 class="text" data-v-e31bd47b>机器学习</h3><!----></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/0.%E8%B7%A8%E5%87%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AD%A5.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>0.跨出深度学习的第一步</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.%E5%9F%BA%E7%A1%80%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>1.基础的线性回归</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2.%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%90%86%E8%AE%BA.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>2.多层感知机理论</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AE%9E%E6%88%98.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>3.多层感知机实战</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>4.卷积神经网络理论</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/5.%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>5.卷积神经网络实战</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>6.循环神经网络理论</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>7.循环神经网络实战</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/8.Transformer.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>8.Transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/9.BERT.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>9.BERT</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5a346dfe data-v-669faec9><div class="VPDoc has-sidebar has-aside" data-v-669faec9 data-v-6b87e69f><!--[--><!--]--><div class="container" data-v-6b87e69f><div class="aside" data-v-6b87e69f><div class="aside-curtain" data-v-6b87e69f></div><div class="aside-container" data-v-6b87e69f><div class="aside-content" data-v-6b87e69f><div class="VPDocAside" data-v-6b87e69f data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-d330b1bb><div class="content" data-v-d330b1bb><div class="outline-marker" data-v-d330b1bb></div><div class="outline-title" role="heading" aria-level="2" data-v-d330b1bb>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-d330b1bb><span class="visually-hidden" id="doc-outline-aria-label" data-v-d330b1bb> Table of Contents for current page </span><ul class="root" data-v-d330b1bb data-v-d0ee3533><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-6b87e69f><div class="content-container" data-v-6b87e69f><!--[--><!--]--><!----><main class="main" data-v-6b87e69f><div style="position:relative;" class="vp-doc _md_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_8_Transformer" data-v-6b87e69f><div><p><img src="/assets/9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw.f6896a2e.png" alt="9olqLl7-x6XtWyNUssHvLGkRzM5cj2_KAPAYU4vaHIw"></p><h1 id="_8-transformer" tabindex="-1">8：Transformer <a class="header-anchor" href="#_8-transformer" aria-label="Permalink to &quot;8：Transformer&quot;">​</a></h1><h2 id="🎯-欢迎进入ai的-核心反应堆" tabindex="-1">🎯 欢迎进入AI的&quot;核心反应堆&quot;！ <a class="header-anchor" href="#🎯-欢迎进入ai的-核心反应堆" aria-label="Permalink to &quot;🎯 欢迎进入AI的&quot;核心反应堆&quot;！&quot;">​</a></h2><p>恭喜你！🎉 经过前面所有题目的历练，你已经从AI小白成功进阶。现在，是时候挑战<strong>现代AI的核心引擎</strong>——<strong>Transformer</strong>了！</p><p>这不仅仅是一道题目，更是一次<strong>从入门到精通</strong>的华丽蜕变！从GPT到ChatGPT，从BERT到Stable Diffusion，几乎所有震撼世界的AI模型都离不开这个神奇的架构。</p><blockquote><p>🚀 <strong>激动人心的事实</strong>: 你即将亲手实现支撑整个大语言模型时代的核心技术！</p></blockquote><h2 id="📚-学习目标" tabindex="-1">📚 学习目标 <a class="header-anchor" href="#📚-学习目标" aria-label="Permalink to &quot;📚 学习目标&quot;">​</a></h2><p>✅ <strong>深入理解</strong> Transformer架构的设计哲学 ✅ <strong>掌握注意力机制</strong>的数学原理 ✅ <strong>MiniGPT实战</strong>：理论转化为代码能力 ✅ <strong>培养独立研究</strong>论文的能力</p><h2 id="💡-学习建议" tabindex="-1">💡 学习建议 <a class="header-anchor" href="#💡-学习建议" aria-label="Permalink to &quot;💡 学习建议&quot;">​</a></h2><ol><li><p><strong>理论先行</strong>: 在写代码之前，确保脑海中有清晰的架构图</p></li><li><p><strong>循序渐进</strong>: 从单头注意力到多头，从简单到复杂</p></li><li><p><strong>善用调试</strong>: 每一个tensor的shape变化都要心中有数</p></li><li><p><strong>对比分析</strong>: 调参数，看变化，做一个&quot;超参数猎人&quot;</p></li><li><p><strong>延伸思考</strong>: 想想如何让你的模型更强更快</p></li></ol><p>⚠️ <strong>重要提醒</strong>: 虽然这题很硬核，但完成后你将<strong>从入门直达精通</strong>！这可能是你编程生涯中最有成就感的时刻之一！同时也是面试中的重点题目喔~</p><h2 id="🔥-第一部分-理论基础问答" tabindex="-1">🔥 第一部分：理论基础问答 <a class="header-anchor" href="#🔥-第一部分-理论基础问答" aria-label="Permalink to &quot;🔥 第一部分：理论基础问答&quot;">​</a></h2><h3 id="attention-is-all-you-need" tabindex="-1">Attention is all you need！ <a class="header-anchor" href="#attention-is-all-you-need" aria-label="Permalink to &quot;Attention is all you need！&quot;">​</a></h3><p>在深入代码之前，让我们先&quot;拷问&quot;一下Transformer的灵魂！</p><p>** 必答题清单：**</p><ol><li><p><strong>Transformer的特点</strong>是什么？主要解决什么问题？缺点又是什么？</p><ul><li>🔍 <strong>任务</strong>: 在原论文中找到对应位置并标注</li></ul></li><li><p><strong>Layer Norm vs Batch Norm</strong></p><ul><li>🤔 这两个&quot;标准化兄弟&quot;有什么恩怨情仇？</li></ul></li><li><p><strong>位置编码 (Positional Encoding)</strong></p><ul><li><p><strong>深度解析</strong>: 什么是位置编码？</p></li><li><p>Transformer用了怎样的位置编码？</p></li><li><p>这种设计的优势在哪里？</p></li></ul></li><li><p><strong>Encoder &amp; Decoder 架构解析</strong></p><ul><li><p><strong>画图 + 文字</strong>: 详细说明两个模块的结构</p></li><li><p>数据是如何在其中流动的？</p></li><li><p>🎯 <strong>面试重点</strong>: 务必搞懂每个细节！</p></li></ul></li><li><p><strong>注意力机制核心问题</strong></p><ul><li><p><strong>K, Q, V</strong>分别代表什么？如何变化？</p></li><li><p><strong>Q×K^T</strong>的数学内涵是什么？</p></li><li><p><strong>Scaled Dot-Product Attention</strong> vs <strong>Additive Attention</strong></p></li></ul></li><li><p><strong>自注意力机制的&quot;自&quot;</strong></p><ul><li>这个&quot;自&quot;字体现在哪里？为什么这么设计？</li></ul></li><li><p><strong>可学习参数分析</strong></p><ul><li><p>注意力机制中有需要学习的参数吗？</p></li><li><p>多头注意力中呢？</p></li><li><p>我们希望这些参数学到什么？</p></li></ul></li><li><p><strong>数据流动全解析</strong></p><ul><li><p>文本输入后，各个维度是如何变化的？</p></li><li><p>从token到embedding到输出的完整过程</p></li></ul></li><li><p><strong>BLEU评估指标</strong></p><ul><li>BLEU是什么？在NLP中扮演什么角色？</li></ul></li></ol><hr><h2 id="第二部分-minigpt实战挑战" tabindex="-1">第二部分：MiniGPT实战挑战 <a class="header-anchor" href="#第二部分-minigpt实战挑战" aria-label="Permalink to &quot;第二部分：MiniGPT实战挑战&quot;">​</a></h2><blockquote><p><em>&quot;纸上得来终觉浅，绝知此事要躬行&quot;</em></p></blockquote><p>准备好撸起袖子，手搓一个<strong>迷你版GPT</strong>了吗？</p><h3 id="🎮-实战环境准备" tabindex="-1">🎮 实战环境准备 <a class="header-anchor" href="#🎮-实战环境准备" aria-label="Permalink to &quot;🎮 实战环境准备&quot;">​</a></h3><p><strong>硬件需求</strong>: 强烈建议使用云端GPU（参考第0题白嫖攻略）</p><p><strong>工具</strong>: Jupyter Lab</p><h3 id="_1️⃣-数据集获取" tabindex="-1">1️⃣ 数据集获取 <a class="header-anchor" href="#_1️⃣-数据集获取" aria-label="Permalink to &quot;1️⃣ 数据集获取&quot;">​</a></h3><p><strong>tinyshakespeare数据集</strong>:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">wget</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">wget</span><span style="color:#24292E;"> </span><span style="color:#032F62;">https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</span></span></code></pre></div><blockquote><p>💡 <strong>偷懒指南</strong>: 数据集很小，直接复制粘贴到txt文件也OK！</p></blockquote><h3 id="_2️⃣-超参数配置" tabindex="-1">2️⃣ 超参数配置 <a class="header-anchor" href="#_2️⃣-超参数配置" aria-label="Permalink to &quot;2️⃣ 超参数配置&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch.nn </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> nn</span></span>
<span class="line"><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> torch.nn </span><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> functional </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> F</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> matplotlib.pyplot </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;">## 超参设置（每个参数都有讲究！）</span></span>
<span class="line"><span style="color:#E1E4E8;">batch_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">16</span><span style="color:#E1E4E8;">     </span><span style="color:#6A737D;"># 批处理大小</span></span>
<span class="line"><span style="color:#E1E4E8;">block_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">32</span><span style="color:#E1E4E8;">     </span><span style="color:#6A737D;"># 上下文长度</span></span>
<span class="line"><span style="color:#E1E4E8;">max_iters </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">5000</span><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 训练轮数</span></span>
<span class="line"><span style="color:#E1E4E8;">learning_rate </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">1e-3</span><span style="color:#E1E4E8;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#E1E4E8;">device </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;cuda&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> torch.cuda.is_available() </span><span style="color:#F97583;">else</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;cpu&#39;</span></span>
<span class="line"><span style="color:#E1E4E8;">n_embd </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">64</span><span style="color:#E1E4E8;">         </span><span style="color:#6A737D;"># embedding维度</span></span>
<span class="line"><span style="color:#E1E4E8;">n_head </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">          </span><span style="color:#6A737D;"># 多头注意力头数</span></span>
<span class="line"><span style="color:#E1E4E8;">n_layer </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">         </span><span style="color:#6A737D;"># transformer层数</span></span>
<span class="line"><span style="color:#E1E4E8;">dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">0.0</span><span style="color:#E1E4E8;">       </span><span style="color:#6A737D;"># dropout率</span></span>
<span class="line"><span style="color:#E1E4E8;">torch.manual_seed(</span><span style="color:#79B8FF;">42</span><span style="color:#E1E4E8;">) </span><span style="color:#6A737D;"># 随机种子，保证可复现</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch.nn </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> nn</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> torch.nn </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> functional </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> F</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;">## 超参设置（每个参数都有讲究！）</span></span>
<span class="line"><span style="color:#24292E;">batch_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">16</span><span style="color:#24292E;">     </span><span style="color:#6A737D;"># 批处理大小</span></span>
<span class="line"><span style="color:#24292E;">block_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">32</span><span style="color:#24292E;">     </span><span style="color:#6A737D;"># 上下文长度</span></span>
<span class="line"><span style="color:#24292E;">max_iters </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">5000</span><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 训练轮数</span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1e-3</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#24292E;">device </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;cuda&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> torch.cuda.is_available() </span><span style="color:#D73A49;">else</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;cpu&#39;</span></span>
<span class="line"><span style="color:#24292E;">n_embd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">64</span><span style="color:#24292E;">         </span><span style="color:#6A737D;"># embedding维度</span></span>
<span class="line"><span style="color:#24292E;">n_head </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">          </span><span style="color:#6A737D;"># 多头注意力头数</span></span>
<span class="line"><span style="color:#24292E;">n_layer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">         </span><span style="color:#6A737D;"># transformer层数</span></span>
<span class="line"><span style="color:#24292E;">dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.0</span><span style="color:#24292E;">       </span><span style="color:#6A737D;"># dropout率</span></span>
<span class="line"><span style="color:#24292E;">torch.manual_seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">) </span><span style="color:#6A737D;"># 随机种子，保证可复现</span></span></code></pre></div><h3 id="_3️⃣-数据预处理" tabindex="-1">3️⃣ 数据预处理 <a class="header-anchor" href="#_3️⃣-数据预处理" aria-label="Permalink to &quot;3️⃣ 数据预处理&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 读取莎士比亚文本</span></span>
<span class="line"><span style="color:#F97583;">with</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">open</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;input.txt&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&#39;r&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">encoding</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;utf-8&#39;</span><span style="color:#E1E4E8;">) </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> f:</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> f.read()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;数据集总字符数: </span><span style="color:#79B8FF;">{len</span><span style="color:#E1E4E8;">(text)</span><span style="color:#F97583;">:,</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;前300个字符预览:</span><span style="color:#79B8FF;">\n{</span><span style="color:#E1E4E8;">text[:</span><span style="color:#79B8FF;">300</span><span style="color:#E1E4E8;">]</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 构建词汇表</span></span>
<span class="line"><span style="color:#E1E4E8;">chars </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">sorted</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">list</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">set</span><span style="color:#E1E4E8;">(text)))</span></span>
<span class="line"><span style="color:#E1E4E8;">vocab_size </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">len</span><span style="color:#E1E4E8;">(chars)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;词汇表: </span><span style="color:#79B8FF;">{</span><span style="color:#9ECBFF;">&#39;&#39;</span><span style="color:#E1E4E8;">.join(chars)</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;词汇表大小: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">vocab_size</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 简单tokenizer实现</span></span>
<span class="line"><span style="color:#E1E4E8;">stoi </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {ch: i </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i, ch </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">enumerate</span><span style="color:#E1E4E8;">(chars)}</span></span>
<span class="line"><span style="color:#E1E4E8;">itos </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {i: ch </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i, ch </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">enumerate</span><span style="color:#E1E4E8;">(chars)}</span></span>
<span class="line"><span style="color:#E1E4E8;">encode </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">lambda</span><span style="color:#E1E4E8;"> s: [stoi[c] </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> c </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> s]</span></span>
<span class="line"><span style="color:#E1E4E8;">decode </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">lambda</span><span style="color:#E1E4E8;"> l: </span><span style="color:#9ECBFF;">&#39;&#39;</span><span style="color:#E1E4E8;">.join([itos[i] </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> i </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> l])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 测试编解码</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;编码测试: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">encode(</span><span style="color:#9ECBFF;">&#39;Hello World!&#39;</span><span style="color:#E1E4E8;">)</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;解码测试: </span><span style="color:#79B8FF;">{</span><span style="color:#E1E4E8;">decode(encode(</span><span style="color:#9ECBFF;">&#39;Hello World!&#39;</span><span style="color:#E1E4E8;">))</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 读取莎士比亚文本</span></span>
<span class="line"><span style="color:#D73A49;">with</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">open</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;input.txt&#39;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">encoding</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;utf-8&#39;</span><span style="color:#24292E;">) </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> f:</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> f.read()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;数据集总字符数: </span><span style="color:#005CC5;">{len</span><span style="color:#24292E;">(text)</span><span style="color:#D73A49;">:,</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;前300个字符预览:</span><span style="color:#005CC5;">\n{</span><span style="color:#24292E;">text[:</span><span style="color:#005CC5;">300</span><span style="color:#24292E;">]</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 构建词汇表</span></span>
<span class="line"><span style="color:#24292E;">chars </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">sorted</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">list</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">set</span><span style="color:#24292E;">(text)))</span></span>
<span class="line"><span style="color:#24292E;">vocab_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(chars)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;词汇表: </span><span style="color:#005CC5;">{</span><span style="color:#032F62;">&#39;&#39;</span><span style="color:#24292E;">.join(chars)</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;词汇表大小: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">vocab_size</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 简单tokenizer实现</span></span>
<span class="line"><span style="color:#24292E;">stoi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {ch: i </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, ch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(chars)}</span></span>
<span class="line"><span style="color:#24292E;">itos </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {i: ch </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, ch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(chars)}</span></span>
<span class="line"><span style="color:#24292E;">encode </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">lambda</span><span style="color:#24292E;"> s: [stoi[c] </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> c </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> s]</span></span>
<span class="line"><span style="color:#24292E;">decode </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">lambda</span><span style="color:#24292E;"> l: </span><span style="color:#032F62;">&#39;&#39;</span><span style="color:#24292E;">.join([itos[i] </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> l])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 测试编解码</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;编码测试: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">encode(</span><span style="color:#032F62;">&#39;Hello World!&#39;</span><span style="color:#24292E;">)</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;解码测试: </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">decode(encode(</span><span style="color:#032F62;">&#39;Hello World!&#39;</span><span style="color:#24292E;">))</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">)</span></span></code></pre></div><h3 id="_4️⃣-数据分批处理" tabindex="-1">4️⃣ 数据分批处理 <a class="header-anchor" href="#_4️⃣-数据分批处理" aria-label="Permalink to &quot;4️⃣ 数据分批处理&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">get_batch</span><span style="color:#E1E4E8;">(split):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#9ECBFF;">    生成训练批次数据</span></span>
<span class="line"><span style="color:#9ECBFF;">    </span></span>
<span class="line"><span style="color:#9ECBFF;">    你需要实现：</span></span>
<span class="line"><span style="color:#9ECBFF;">    1. 从训练/验证集中随机采样</span></span>
<span class="line"><span style="color:#9ECBFF;">    2. 生成输入序列x和目标序列y  </span></span>
<span class="line"><span style="color:#9ECBFF;">    3. 返回正确维度的tensor</span></span>
<span class="line"><span style="color:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 你的代码在这里</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">get_batch</span><span style="color:#24292E;">(split):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    生成训练批次数据</span></span>
<span class="line"><span style="color:#032F62;">    </span></span>
<span class="line"><span style="color:#032F62;">    你需要实现：</span></span>
<span class="line"><span style="color:#032F62;">    1. 从训练/验证集中随机采样</span></span>
<span class="line"><span style="color:#032F62;">    2. 生成输入序列x和目标序列y  </span></span>
<span class="line"><span style="color:#032F62;">    3. 返回正确维度的tensor</span></span>
<span class="line"><span style="color:#032F62;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 你的代码在这里</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span></code></pre></div><h3 id="_5️⃣-模型架构实现" tabindex="-1">5️⃣ 模型架构实现 <a class="header-anchor" href="#_5️⃣-模型架构实现" aria-label="Permalink to &quot;5️⃣ 模型架构实现&quot;">​</a></h3><p><strong>🔥 这是整个项目的核心！必须手工实现！</strong></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">Head</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;单头自注意力&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, head_size):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># QKV投影矩阵</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.key </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.query </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">) </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.value </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, head_size, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 下三角mask矩阵（防止看到未来）</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.register_buffer(</span><span style="color:#9ECBFF;">&#39;tril&#39;</span><span style="color:#E1E4E8;">, torch.tril(torch.ones(block_size, block_size)))</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        B, T, C </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> x.shape</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 注意力计算逻辑</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 1. 计算Q, K, V</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 2. 计算注意力分数</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 3. 应用mask</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 4. 加权求和</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">MultiHeadAttention</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;多头注意力：并行处理多个注意力头&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, num_heads, head_size):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.heads </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.ModuleList([Head(head_size) </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(num_heads)])</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.proj </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.dropout </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 多头并行计算与合并</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">FeedForward</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;前馈神经网络：简单而强大&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 实现两层线性变换+激活</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">Block</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;Transformer Block：communication + computation&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 组装完整的transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># LayerNorm + MultiHeadAttention + LayerNorm + FeedForward</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">BigramLanguageModel</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;完整的语言模型&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">().</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># embedding表</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.token_embedding_table </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Embedding(vocab_size, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.position_embedding_table </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Embedding(block_size, n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 堆叠transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.blocks </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Sequential(</span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;">[Block(n_embd, </span><span style="color:#FFAB70;">n_head</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">n_head) </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(n_layer)])</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.ln_f </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.LayerNorm(n_embd)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.lm_head </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(n_embd, vocab_size)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, idx, targets</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 完整前向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 1. token + position embedding</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 2. 通过transformer块</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 3. 输出预测</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 4. 计算损失（如果有target）</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">pass</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">generate</span><span style="color:#E1E4E8;">(self, idx, max_new_tokens):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#9ECBFF;">&quot;&quot;&quot;文本生成：让AI说话！&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(max_new_tokens):</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 裁剪到block_size</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx_cond </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> idx[:, </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">block_size:]</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 预测下一个token</span></span>
<span class="line"><span style="color:#E1E4E8;">            logits, _ </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">(idx_cond)</span></span>
<span class="line"><span style="color:#E1E4E8;">            logits </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> logits[:, </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, :]  </span><span style="color:#6A737D;"># 只要最后一个时间步</span></span>
<span class="line"><span style="color:#E1E4E8;">            probs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> F.softmax(logits, </span><span style="color:#FFAB70;">dim</span><span style="color:#F97583;">=-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#6A737D;"># 采样下一个token</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx_next </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.multinomial(probs, </span><span style="color:#FFAB70;">num_samples</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">            idx </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.cat((idx, idx_next), </span><span style="color:#FFAB70;">dim</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> idx</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">Head</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;单头自注意力&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, head_size):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># QKV投影矩阵</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.key </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.query </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">) </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.value </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, head_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 下三角mask矩阵（防止看到未来）</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.register_buffer(</span><span style="color:#032F62;">&#39;tril&#39;</span><span style="color:#24292E;">, torch.tril(torch.ones(block_size, block_size)))</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        B, T, C </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x.shape</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 注意力计算逻辑</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 1. 计算Q, K, V</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 2. 计算注意力分数</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 3. 应用mask</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 4. 加权求和</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">MultiHeadAttention</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;多头注意力：并行处理多个注意力头&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, num_heads, head_size):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.heads </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.ModuleList([Head(head_size) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_heads)])</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dropout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Dropout(dropout)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 多头并行计算与合并</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">FeedForward</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;前馈神经网络：简单而强大&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现两层线性变换+激活</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">Block</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;Transformer Block：communication + computation&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 组装完整的transformer块</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># LayerNorm + MultiHeadAttention + LayerNorm + FeedForward</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">BigramLanguageModel</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;完整的语言模型&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># embedding表</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.token_embedding_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Embedding(vocab_size, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.position_embedding_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Embedding(block_size, n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 堆叠transformer块</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.blocks </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Sequential(</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">[Block(n_embd, </span><span style="color:#E36209;">n_head</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">n_head) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_layer)])</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.ln_f </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.LayerNorm(n_embd)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.lm_head </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(n_embd, vocab_size)</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, idx, targets</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 完整前向传播</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 1. token + position embedding</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 2. 通过transformer块</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 3. 输出预测</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 4. 计算损失（如果有target）</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">pass</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">generate</span><span style="color:#24292E;">(self, idx, max_new_tokens):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;文本生成：让AI说话！&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(max_new_tokens):</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 裁剪到block_size</span></span>
<span class="line"><span style="color:#24292E;">            idx_cond </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> idx[:, </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">block_size:]</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 预测下一个token</span></span>
<span class="line"><span style="color:#24292E;">            logits, _ </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">(idx_cond)</span></span>
<span class="line"><span style="color:#24292E;">            logits </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> logits[:, </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, :]  </span><span style="color:#6A737D;"># 只要最后一个时间步</span></span>
<span class="line"><span style="color:#24292E;">            probs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> F.softmax(logits, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#6A737D;"># 采样下一个token</span></span>
<span class="line"><span style="color:#24292E;">            idx_next </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.multinomial(probs, </span><span style="color:#E36209;">num_samples</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            idx </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.cat((idx, idx_next), </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> idx</span></span></code></pre></div><h3 id="_6️⃣-模型评估-📊" tabindex="-1">6️⃣ 模型评估 📊 <a class="header-anchor" href="#_6️⃣-模型评估-📊" aria-label="Permalink to &quot;6️⃣ 模型评估 📊&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">@torch.no_grad</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">estimate_loss</span><span style="color:#E1E4E8;">():</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;评估训练和验证损失&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {}</span></span>
<span class="line"><span style="color:#E1E4E8;">    model.eval()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 计算平均损失</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    model.train()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> out</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">@torch.no_grad</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">estimate_loss</span><span style="color:#24292E;">():</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;评估训练和验证损失&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {}</span></span>
<span class="line"><span style="color:#24292E;">    model.eval()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 计算平均损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    model.train()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> out</span></span></code></pre></div><h3 id="_7️⃣-模型训练" tabindex="-1">7️⃣ 模型训练 <a class="header-anchor" href="#_7️⃣-模型训练" aria-label="Permalink to &quot;7️⃣ 模型训练&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 实例化模型</span></span>
<span class="line"><span style="color:#E1E4E8;">model </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> BigramLanguageModel().to(device)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">f</span><span style="color:#9ECBFF;">&quot;模型参数量: </span><span style="color:#79B8FF;">{sum</span><span style="color:#E1E4E8;">(p.numel() </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> p </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> model.parameters())</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">1e6</span><span style="color:#F97583;">:.2f</span><span style="color:#79B8FF;">}</span><span style="color:#9ECBFF;">M&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 训练循环</span></span>
<span class="line"><span style="color:#E1E4E8;">optimizer </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.optim.AdamW(model.parameters(), </span><span style="color:#FFAB70;">lr</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">learning_rate)</span></span>
<span class="line"><span style="color:#E1E4E8;">train_losses, val_losses </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">iter</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(max_iters):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 训练循环实现</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 1. 获取batch</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 2. 前向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 3. 计算损失</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 4. 反向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 5. 参数更新</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 6. 定期评估</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 绘制损失曲线</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.figure(</span><span style="color:#FFAB70;">figsize</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">5</span><span style="color:#E1E4E8;">))</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.plot(train_losses, </span><span style="color:#FFAB70;">label</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;Train Loss&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">color</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;#FF6B6B&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.plot(val_losses, </span><span style="color:#FFAB70;">label</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;Validation Loss&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">color</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;#4ECDC4&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.xlabel(</span><span style="color:#9ECBFF;">&#39;Iteration&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.ylabel(</span><span style="color:#9ECBFF;">&#39;Loss&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.title(</span><span style="color:#9ECBFF;">&#39;Training Progress: Loss Curves&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.legend()</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.grid(</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">alpha</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0.3</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">plt.savefig(</span><span style="color:#9ECBFF;">&#39;loss_plot.png&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">dpi</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">300</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bbox_inches</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;tight&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 生成莎士比亚风格文本</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;AI莎士比亚开始创作...&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">context </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.zeros((</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">), </span><span style="color:#FFAB70;">dtype</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">torch.long, </span><span style="color:#FFAB70;">device</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">device)</span></span>
<span class="line"><span style="color:#E1E4E8;">generated_text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> decode(model.generate(context, </span><span style="color:#FFAB70;">max_new_tokens</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2000</span><span style="color:#E1E4E8;">)[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">].tolist())</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(generated_text)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 实例化模型</span></span>
<span class="line"><span style="color:#24292E;">model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> BigramLanguageModel().to(device)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;模型参数量: </span><span style="color:#005CC5;">{sum</span><span style="color:#24292E;">(p.numel() </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> p </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> model.parameters())</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">1e6</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">M&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 训练循环</span></span>
<span class="line"><span style="color:#24292E;">optimizer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.optim.AdamW(model.parameters(), </span><span style="color:#E36209;">lr</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">learning_rate)</span></span>
<span class="line"><span style="color:#24292E;">train_losses, val_losses </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">iter</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(max_iters):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 训练循环实现</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 1. 获取batch</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 2. 前向传播</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 3. 计算损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 4. 反向传播</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 5. 参数更新</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 6. 定期评估</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">###################</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 绘制损失曲线</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(train_losses, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train Loss&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">color</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;#FF6B6B&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(val_losses, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Validation Loss&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">color</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;#4ECDC4&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iteration&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Loss&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Training Progress: Loss Curves&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.grid(</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">, </span><span style="color:#E36209;">alpha</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.3</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.savefig(</span><span style="color:#032F62;">&#39;loss_plot.png&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dpi</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">300</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bbox_inches</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;tight&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 生成莎士比亚风格文本</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;AI莎士比亚开始创作...&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">context </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.zeros((</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">), </span><span style="color:#E36209;">dtype</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">torch.long, </span><span style="color:#E36209;">device</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">device)</span></span>
<span class="line"><span style="color:#24292E;">generated_text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> decode(model.generate(context, </span><span style="color:#E36209;">max_new_tokens</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2000</span><span style="color:#24292E;">)[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].tolist())</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(generated_text)</span></span></code></pre></div><h3 id="_8️⃣-结果分析" tabindex="-1">8️⃣ 结果分析 <a class="header-anchor" href="#_8️⃣-结果分析" aria-label="Permalink to &quot;8️⃣ 结果分析&quot;">​</a></h3><p><strong>回答以下问题：</strong></p><ol><li><p><strong>Validation Loss收敛值</strong>是多少？</p></li><li><p><strong>MiniGPT参数量</strong>统计（应该&lt;1M）</p></li><li><p><strong>显存占用</strong>情况（应该&lt;1G）</p></li></ol><h3 id="_9️⃣-挑战性进阶问题" tabindex="-1">9️⃣ 挑战性进阶问题 <a class="header-anchor" href="#_9️⃣-挑战性进阶问题" aria-label="Permalink to &quot;9️⃣ 挑战性进阶问题&quot;">​</a></h3><ol><li><p><strong>RoPE vs 正弦位置编码</strong></p><ul><li><p>为什么现代GPT使用<strong>Rotary Position Embedding</strong>？</p></li><li><p>尝试在MiniGPT中实现RoPE并对比性能！</p></li></ul></li><li><p><strong>LayerNorm位置之争</strong></p><ul><li><p><strong>Pre-LN</strong> vs <strong>Post-LN</strong>：为什么前者更稳定？</p></li><li><p>修改代码实现Pre-LN架构并分析训练稳定性！</p></li></ul></li><li><p><strong>计算复杂度分析</strong></p><ul><li><p>当block_size增加到128时会发生什么？</p></li><li><p>尝试**梯度检查点(Gradient Checkpointing)**减少显存占用！</p></li></ul></li><li><p><strong>FlashAttention算法</strong></p><ul><li>了解这个让Transformer飞起来的神奇算法！</li></ul></li></ol><hr><h2 id="⚠️-重要提醒" tabindex="-1">⚠️ 重要提醒 <a class="header-anchor" href="#⚠️-重要提醒" aria-label="Permalink to &quot;⚠️ 重要提醒&quot;">​</a></h2><blockquote><p><strong>AI工具使用</strong>: 本题<strong>强烈建议纯手工实现</strong>！这可能是你最后一次有机会完全从零手撸这么核心的算法了，好好珍惜这个过程吧！</p></blockquote><hr><h2 id="提交要求" tabindex="-1">提交要求 <a class="header-anchor" href="#提交要求" aria-label="Permalink to &quot;提交要求&quot;">​</a></h2><h3 id="提交内容" tabindex="-1">提交内容 <a class="header-anchor" href="#提交内容" aria-label="Permalink to &quot;提交内容&quot;">​</a></h3><ul><li><p><strong>代码文件</strong>: <code>ml-8-姓名-学号.py</code></p></li><li><p><strong>理论答案</strong>: <code>ml-8-姓名-学号.md</code></p></li><li><p>压缩包提交</p></li></ul><h3 id="提交方式" tabindex="-1">提交方式 <a class="header-anchor" href="#提交方式" aria-label="Permalink to &quot;提交方式&quot;">​</a></h3><ul><li><p><strong>邮箱</strong>: <code>gimmerml401@163.com</code></p></li><li><p><strong>主题</strong>: <code>8-姓名-学号</code></p></li></ul><blockquote><p>出题人：百事可乐</p><p>QQ：2465800571</p></blockquote></div></div></main><footer class="VPDocFooter" data-v-6b87e69f data-v-ef5dee53><!--[--><!--]--><!----><nav class="prev-next" data-v-ef5dee53><div class="pager" data-v-ef5dee53><a class="pager-link prev" href="./7.%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98.html" data-v-ef5dee53><span class="desc" data-v-ef5dee53>Previous page</span><span class="title" data-v-ef5dee53>7.循环神经网络实战</span></a></div><div class="pager" data-v-ef5dee53><a class="pager-link next" href="./9.BERT.html" data-v-ef5dee53><span class="desc" data-v-ef5dee53>Next page</span><span class="title" data-v-ef5dee53>9.BERT</span></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5a346dfe data-v-e03eb2e1><div class="container" data-v-e03eb2e1><!----><p class="copyright" data-v-e03eb2e1>Copyright © 2025 glimmer || <a href="https://beian.miit.gov.cn/">蜀ICP备2025159949号-2</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"md_前端_t4.javascript入门和进阶.md\":\"e5362256\",\"md_日常基础_日常-06：代码管理.md\":\"72360c55\",\"md_前端_t3.css初识.md\":\"3c6a6349\",\"md_计算机系统_cs-medium-01-位计算.md\":\"14f1283e\",\"md_机器学习_9.bert.md\":\"18f56635\",\"md_前端_t1.初识html.md\":\"6e838ebf\",\"md_后端_java09-io流.md\":\"1bf1ed58\",\"md_后端_java04-控制流.md\":\"6dd16958\",\"md_日常基础_日常-01：什么是计算机？.md\":\"ce0dda49\",\"md_后端_java03-数据类型与数据结构.md\":\"e2a9c27a\",\"md_后端_java02-程序运行.md\":\"3b2d0b14\",\"md_日常基础_日常-04：ide编程前的准备.md\":\"53adff6c\",\"index.md\":\"7ee827fc\",\"md_机器学习_index.md\":\"94dd706e\",\"md_计算机系统_计算机系统方向总述.md\":\"b5ab7e55\",\"md_前端_t6.第三方api__排序.md\":\"f976b59f\",\"md_计算机系统_index.md\":\"4924db7e\",\"md_计算机系统_cs-hard-01-cache.md\":\"6f1c67f3\",\"md_机器学习_1.基础的线性回归.md\":\"aa6ca61b\",\"md_计算机系统_cs-easy-03 编译原理引入.md\":\"f2330262\",\"md_后端_java07-集合与泛型.md\":\"5945f2f9\",\"md_机器学习_0.跨出深度学习的第一步.md\":\"86f67ca4\",\"md_前端_index.md\":\"20e7996d\",\"md_日常基础_index.md\":\"bbcb4bc2\",\"md_前端_t7.node.js.md\":\"37410f8a\",\"md_机器学习_5.卷积神经网络实战.md\":\"76a55d47\",\"md_后端_java06-封装继承与多态.md\":\"d2677197\",\"md_qa.md\":\"2f244abc\",\"md_前端_t5.制作blog.md\":\"9a3d250f\",\"md_机器学习_2.多层感知机理论.md\":\"f499ddc7\",\"md_后端_index.md\":\"f1a651ce\",\"md_前端_t8.vitepress.md\":\"c586e7c3\",\"md_后端_java01-环境搭建.md\":\"83f4bf8f\",\"md_后端_java08-异常处理与stream流.md\":\"f6f7fa8b\",\"md_前端_t9.vue的学习.md\":\"df8a1210\",\"md_提示.md\":\"2188776d\",\"md_后端_java10-快递取件码查询项目.md\":\"6bf77576\",\"md_方向简介_其他渠道招新说明.md\":\"7bf7db45\",\"md_机器学习_4.卷积神经网络理论.md\":\"1f687eed\",\"md_日常基础_日常-05：了解linux.md\":\"eded2606\",\"md_日常基础_日常-07：loafer想打派(网络).md\":\"9f747288\",\"md_机器学习_3.多层感知机实战.md\":\"6fe2e391\",\"md_计算机系统_cs-easy-01 what's your name.md\":\"e89020ab\",\"md_计算机系统_cs-easy-02 基础数据结构.md\":\"94dc59d6\",\"md_日常基础_日常-03：数据的表示.md\":\"945da243\",\"md_计算机系统_cs-medium-04 计算机网络常识与实验.md\":\"07f6de10\",\"md_前端_t2.了解网页f12开发者工具.md\":\"648280dd\",\"md_机器学习_6.循环神经网络理论.md\":\"09fe7d10\",\"md_招新说明.md\":\"2b9f5184\",\"md_后端_java05-面向对象.md\":\"05340436\",\"md_日常基础_日常-02：markdown.md\":\"a1fcded6\",\"md_机器学习_8.transformer.md\":\"b9a92191\",\"md_计算机系统_cs-medium-03 read from memory.md\":\"56b77e09\",\"md_机器学习_7.循环神经网络实战.md\":\"80f846d4\",\"md_计算机系统_cs-medium-02-浮点数.md\":\"a4945249\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"2025招新\",\"description\":\"A VitePress site\",\"base\":\"/\",\"head\":[],\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"微光工作室\",\"logo\":\"/image/favicon.png\",\"nav\":[{\"text\":\"招新说明\",\"link\":\"/md/招新说明.md\"},{\"text\":\"日常基础\",\"activeMatch\":\"/md/日常基础/\",\"items\":[{\"text\":\"日常-01：什么是计算机？\",\"link\":\"/md/日常基础/日常-01：什么是计算机？.md\"},{\"text\":\"日常-02：markdown\",\"link\":\"/md/日常基础/日常-02：markdown.md\"},{\"text\":\"日常-03：数据的表示\",\"link\":\"/md/日常基础/日常-03：数据的表示.md\"},{\"text\":\"日常-04：IDE编程前的准备\",\"link\":\"/md/日常基础/日常-04：IDE编程前的准备.md\"},{\"text\":\"日常-05：了解linux\",\"link\":\"/md/日常基础/日常-05：了解linux.md\"},{\"text\":\"日常-06：代码管理\",\"link\":\"/md/日常基础/日常-06：代码管理.md\"},{\"text\":\"日常-07：loafer想打派(网络)\",\"link\":\"/md/日常基础/日常-07：loafer想打派(网络).md\"}]},{\"text\":\"计算机系统\",\"items\":[{\"text\":\"计算机系统简介\",\"link\":\"/md/计算机系统/\"},{\"text\":\"计算机系统\",\"items\":[{\"text\":\"CS-EASY-01 What's your name\",\"link\":\"/md/计算机系统/CS-EASY-01 What's your name.md\"},{\"text\":\"CS-EASY-02 基础数据结构\",\"link\":\"/md/计算机系统/CS-EASY-02 基础数据结构.md\"},{\"text\":\"CS-EASY-03 编译原理引入\",\"link\":\"/md/计算机系统/CS-EASY-03 编译原理引入.md\"},{\"text\":\"CS-MEDIUM-01-位计算\",\"link\":\"/md/计算机系统/CS-MEDIUM-01-位计算.md\"},{\"text\":\"CS-MEDIUM-02-浮点数\",\"link\":\"/md/计算机系统/CS-MEDIUM-02-浮点数.md\"},{\"text\":\"CS-MEDIUM-03 Read From Memory\",\"link\":\"/md/计算机系统/CS-MEDIUM-03 Read From Memory.md\"},{\"text\":\"CS-MEDIUM-04 计算机网络常识与实验\",\"link\":\"/md/计算机系统/CS-MEDIUM-04 计算机网络常识与实验.md\"},{\"text\":\"CS-HARD-01-cache\",\"link\":\"/md/计算机系统/CS-HARD-01-cache.md\"}]}]},{\"text\":\"前端\",\"items\":[{\"text\":\"前端简介\",\"link\":\"/md/前端/\"},{\"text\":\"前端\",\"items\":[{\"text\":\"前端方向-01：初识HTML\",\"link\":\"/md/前端/T1.初识HTML.md\"},{\"text\":\"前端方向-02：了解网页F12开发者工具\",\"link\":\"/md/前端/T2.了解网页F12开发者工具.md\"},{\"text\":\"前端方向-03：CSS初识\",\"link\":\"/md/前端/T3.CSS初识.md\"},{\"text\":\"前端方向-04：Javascript入门和进阶\",\"link\":\"/md/前端/T4.Javascript入门和进阶.md\"},{\"text\":\"前端方向-05：制作blog\",\"link\":\"/md/前端/T5.制作blog.md\"},{\"text\":\"前端方向-06：第三方API&&排序\",\"link\":\"/md/前端/T6.第三方API&&排序.md\"},{\"text\":\"前端方向-07：Node.js\",\"link\":\"/md/前端/T7.Node.js.md\"},{\"text\":\"前端方向-08：VitePress\",\"link\":\"/md/前端/T8.VitePress.md\"},{\"text\":\"前端方向-09：Vue的学习\",\"link\":\"/md/前端/T9.Vue的学习.md\"}]}]},{\"text\":\"后端\",\"items\":[{\"text\":\"后端简介\",\"link\":\"/md/后端/\"},{\"text\":\"JAVA\",\"items\":[{\"text\":\"Java01-环境搭建\",\"link\":\"/md/后端/Java01-环境搭建.md\"},{\"text\":\"Java02-程序运行\",\"link\":\"/md/后端/Java02-程序运行.md\"},{\"text\":\"Java03-数据类型与数据结构\",\"link\":\"/md/后端/Java03-数据类型与数据结构.md\"},{\"text\":\"Java04-控制流\",\"link\":\"/md/后端/Java04-控制流.md\"},{\"text\":\"Java05-面向对象\",\"link\":\"/md/后端/Java05-面向对象.md\"},{\"text\":\"Java06-封装继承与多态\",\"link\":\"/md/后端/Java06-封装继承与多态.md\"},{\"text\":\"java07-集合与泛型\",\"link\":\"/md/后端/java07-集合与泛型.md\"},{\"text\":\"java08-异常处理与Stream流\",\"link\":\"/md/后端/java08-异常处理与Stream流.md\"},{\"text\":\"java09-IO流\",\"link\":\"/md/后端/java09-IO流.md\"},{\"text\":\"Java10-快递取件码查询项目\",\"link\":\"/md/后端/Java10-快递取件码查询项目.md\"}]}]},{\"text\":\"机器学习\",\"items\":[{\"text\":\"机器学习简介\",\"link\":\"/md/机器学习/\"},{\"text\":\"机器学习\",\"items\":[{\"text\":\"0.跨出深度学习的第一步\",\"link\":\"/md/机器学习/0.跨出深度学习的第一步.md\"},{\"text\":\"1.基础的线性回归\",\"link\":\"/md/机器学习/1.基础的线性回归\"},{\"text\":\"2.多层感知机理论\",\"link\":\"/md/机器学习/2.多层感知机理论.md\"},{\"text\":\"3.多层感知机实战\",\"link\":\"/md/机器学习/3.多层感知机实战.md\"},{\"text\":\"4.卷积神经网络理论\",\"link\":\"/md/机器学习/4.卷积神经网络理论.md\"},{\"text\":\"5.卷积神经网络实战\",\"link\":\"/md/机器学习/5.卷积神经网络实战.md\"},{\"text\":\"6.循环神经网络理论\",\"link\":\"/md/机器学习/6.循环神经网络理论.md\"},{\"text\":\"7.循环神经网络实战\",\"link\":\"/md/机器学习/7.循环神经网络实战.md\"},{\"text\":\"8.Transformer\",\"link\":\"/md/机器学习/8.Transformer.md\"},{\"text\":\"9.BERT\",\"link\":\"/md/机器学习/9.BERT.md\"}]}]}],\"sidebar\":{\"/md/日常基础/\":[{\"text\":\"日常基础\",\"items\":[{\"text\":\"日常-01：什么是计算机？\",\"link\":\"/md/日常基础/日常-01：什么是计算机？.md\"},{\"text\":\"日常-02：markdown\",\"link\":\"/md/日常基础/日常-02：markdown.md\"},{\"text\":\"日常-03：数据的表示\",\"link\":\"/md/日常基础/日常-03：数据的表示.md\"},{\"text\":\"日常-04：IDE编程前的准备\",\"link\":\"/md/日常基础/日常-04：IDE编程前的准备.md\"},{\"text\":\"日常-05：了解linux\",\"link\":\"/md/日常基础/日常-05：了解linux.md\"},{\"text\":\"日常-06：代码管理\",\"link\":\"/md/日常基础/日常-06：代码管理.md\"},{\"text\":\"日常-07：loafer想打派(网络)\",\"link\":\"/md/日常基础/日常-07：loafer想打派(网络)\"}]}],\"/md/计算机系统/\":[{\"text\":\"计算机系统\",\"items\":[{\"text\":\"计算机系统简介\",\"link\":\"/md/计算机系统/\"},{\"text\":\"计算机系统\",\"items\":[{\"text\":\"CS-EASY-01 What's your name\",\"link\":\"/md/计算机系统/CS-EASY-01 What's your name.md\"},{\"text\":\"CS-EASY-02 基础数据结构\",\"link\":\"/md/计算机系统/CS-EASY-02 基础数据结构.md\"},{\"text\":\"CS-EASY-03 编译原理引入\",\"link\":\"/md/计算机系统/CS-EASY-03 编译原理引入.md\"},{\"text\":\"CS-MEDIUM-01-位计算\",\"link\":\"/md/计算机系统/CS-MEDIUM-01-位计算.md\"},{\"text\":\"CS-MEDIUM-02-浮点数\",\"link\":\"/md/计算机系统/CS-MEDIUM-02-浮点数.md\"},{\"text\":\"CS-MEDIUM-03 Read From Memory\",\"link\":\"/md/计算机系统/CS-MEDIUM-03 Read From Memory.md\"},{\"text\":\"CS-MEDIUM-04 计算机网络常识与实验\",\"link\":\"/md/计算机系统/CS-MEDIUM-04 计算机网络常识与实验.md\"},{\"text\":\"CS-HARD-01-cache\",\"link\":\"/md/计算机系统/CS-HARD-01-cache.md\"}]}]}],\"/md/前端/\":[{\"text\":\"前端\",\"link\":\"/md/前端/\",\"items\":[{\"text\":\"前端简介\",\"link\":\"/md/前端/\"},{\"text\":\"前端\",\"items\":[{\"text\":\"前端方向-01：初识HTML\",\"link\":\"/md/前端/T1.初识HTML.md\"},{\"text\":\"前端方向-02：了解网页F12开发者工具\",\"link\":\"/md/前端/T2.了解网页F12开发者工具.md\"},{\"text\":\"前端方向-03：CSS初识\",\"link\":\"/md/前端/T3.CSS初识.md\"},{\"text\":\"前端方向-04：Javascript入门和进阶\",\"link\":\"/md/前端/T4.Javascript入门和进阶.md\"},{\"text\":\"前端方向-05：制作blog\",\"link\":\"/md/前端/T5.制作blog.md\"},{\"text\":\"前端方向-06：第三方API&&排序\",\"link\":\"/md/前端/T6.第三方API&&排序.md\"},{\"text\":\"前端方向-07：Node.js\",\"link\":\"/md/前端/T7.Node.js.md\"},{\"text\":\"前端方向-08：VitePress\",\"link\":\"/md/前端/T8.VitePress.md\"},{\"text\":\"前端方向-09：Vue的学习\",\"link\":\"/md/前端/T9.Vue的学习.md\"}]}]}],\"/md/后端/\":[{\"text\":\"后端\",\"items\":[{\"text\":\"后端简介\",\"link\":\"/md/后端/\"},{\"text\":\"JAVA\",\"items\":[{\"text\":\"Java01-环境搭建\",\"link\":\"/md/后端/Java01-环境搭建.md\"},{\"text\":\"Java02-程序运行\",\"link\":\"/md/后端/Java02-程序运行.md\"},{\"text\":\"Java03-数据类型与数据结构\",\"link\":\"/md/后端/Java03-数据类型与数据结构.md\"},{\"text\":\"Java04-控制流\",\"link\":\"/md/后端/Java04-控制流.md\"},{\"text\":\"Java05-面向对象\",\"link\":\"/md/后端/Java05-面向对象.md\"},{\"text\":\"Java06-封装继承与多态\",\"link\":\"/md/后端/Java06-封装继承与多态.md\"},{\"text\":\"java07-集合与泛型\",\"link\":\"/md/后端/java07-集合与泛型.md\"},{\"text\":\"java08-异常处理与Stream流\",\"link\":\"/md/后端/java08-异常处理与Stream流.md\"},{\"text\":\"java09-IO流\",\"link\":\"/md/后端/java09-IO流.md\"},{\"text\":\"Java10-快递取件码查询项目\",\"link\":\"/md/后端/Java10-快递取件码查询项目.md\"}]}]}],\"/md/机器学习/\":[{\"text\":\"机器学习\",\"link\":\"/md/机器学习/\",\"items\":[{\"text\":\"机器学习简介\",\"link\":\"/md/机器学习/\"},{\"text\":\"机器学习\",\"items\":[{\"text\":\"0.跨出深度学习的第一步\",\"link\":\"/md/机器学习/0.跨出深度学习的第一步.md\"},{\"text\":\"1.基础的线性回归\",\"link\":\"/md/机器学习/1.基础的线性回归\"},{\"text\":\"2.多层感知机理论\",\"link\":\"/md/机器学习/2.多层感知机理论.md\"},{\"text\":\"3.多层感知机实战\",\"link\":\"/md/机器学习/3.多层感知机实战.md\"},{\"text\":\"4.卷积神经网络理论\",\"link\":\"/md/机器学习/4.卷积神经网络理论.md\"},{\"text\":\"5.卷积神经网络实战\",\"link\":\"/md/机器学习/5.卷积神经网络实战.md\"},{\"text\":\"6.循环神经网络理论\",\"link\":\"/md/机器学习/6.循环神经网络理论.md\"},{\"text\":\"7.循环神经网络实战\",\"link\":\"/md/机器学习/7.循环神经网络实战.md\"},{\"text\":\"8.Transformer\",\"link\":\"/md/机器学习/8.Transformer.md\"},{\"text\":\"9.BERT\",\"link\":\"/md/机器学习/9.BERT.md\"}]}]}]},\"socialLinks\":[{\"icon\":\"slack\",\"link\":\"https://glimmer.org.cn/\"}],\"footer\":{\"message\":\"\",\"copyright\":\"Copyright © 2025 glimmer || <a href=\\\"https://beian.miit.gov.cn/\\\">蜀ICP备2025159949号-2</a>\"}},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>